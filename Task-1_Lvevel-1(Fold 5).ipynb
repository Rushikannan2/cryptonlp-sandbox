{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255,
     "referenced_widgets": [
      "7a8204f362964d5d923cbfa49dfdaa7c",
      "ba69d252355f4dfbb83720c4fb37adef",
      "e0735c4c6180424e90b999e84ed41439",
      "6945d0bcf19b489fbdef85b678f70d90",
      "b5df97ec6d304e54a8adba89f3847ca4",
      "efd0cc34ffcd48a5966f7b723a540740",
      "bb7d161893e24d2a9a3fe0495f28005a",
      "05568fd1f3e84bc5b5c71054974f68b3",
      "3f6bedae5d7d4ea8bc0dbbc3b0a6284d",
      "b333f29e60e540e291cd4a8b3c611eb6",
      "4fdfb6a9358a4cff9670eaa470af2492",
      "1b045c92c5c44350948750c8f6c833a2",
      "fd89f9d29fba442c87c7ff8032840c45",
      "d13222378b4a4f74ac2e40e000180b8b",
      "658e58175e984919a679871f6a83c570",
      "40964608f6f24173aa405082626ec76f",
      "de6ddcf364bd49348885bab3d93becaa",
      "c9aadc62f1c04a8b9c4f0ca3b70ab0bb",
      "5d8192e375f24d8396c267292d4213e6",
      "0cec8cefce724b29bcf40399a67dc1d8",
      "15cf8c0a86e44c43801dd3a9ccee7733",
      "2964fc1ecf47403b8159606a4545f80d",
      "02d2a68528d44bda96b17738e40766db",
      "89445f13c88e486fb5e5d2b9ade14506",
      "8b728c1eccdb4e249f4b162e3d4e5b62",
      "44723cd190604e36b94846e0bc768cab",
      "a7f5bbe8d12c406f884945d99edcbad7",
      "c3ee64087d054ae79fcf90f2046dea20",
      "21908f165b754acbbaf74c358792812a",
      "26d56c987acb4f7886c171a67e4f01f3",
      "b931439a66e34884be5bd75798ebc870",
      "993fa1ab4ee94306a192542d7e56a619",
      "de6f0a9be05f44f2aa28d3430711e314"
     ]
    },
    "executionInfo": {
     "elapsed": 22881,
     "status": "ok",
     "timestamp": 1751095719663,
     "user": {
      "displayName": "RUSHI KANNAN",
      "userId": "14122798334208989020"
     },
     "user_tz": -330
    },
    "id": "mdV6QNvoY0tQ",
    "outputId": "1129d600-33c3-43c4-a6c7-50845f234da1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8204f362964d5d923cbfa49dfdaa7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b045c92c5c44350948750c8f6c833a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d2a68528d44bda96b17738e40766db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import mode\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import (\n",
    "    DebertaV2Tokenizer,\n",
    "    DebertaV2ForSequenceClassification,\n",
    "    get_scheduler\n",
    ")\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Configuration --------------------\n",
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "VAL_BATCH_SIZE = 32\n",
    "MAX_LENGTH = 128\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-5\n",
    "PATIENCE = 2\n",
    "MODEL_NAME = 'microsoft/deberta-v3-small'\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/FIRE/outputs\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "# -------------------- Seed Setup --------------------\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- Tokenizer --------------------\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, \"tokenizer\"))\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CryptoDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "def collate_fn(batch):\n",
    "    keys = batch[0].keys()\n",
    "    return {key: torch.stack([item[key] for item in batch]) for key in keys}\n",
    "\n",
    "\n",
    "# -------------------- Confusion Matrix --------------------\n",
    "def plot_confusion_matrix(labels, preds, classes, title, save_path):\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# -------------------- Contrastive Supervision --------------------\n",
    "def apply_contrastive_supervision(features, labels, temperature=0.1):\n",
    "    features = F.normalize(features, dim=1)\n",
    "    similarity_matrix = torch.matmul(features, features.T)\n",
    "    labels = labels.contiguous().view(-1, 1)\n",
    "    mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "    logits = similarity_matrix / temperature\n",
    "    logits_mask = torch.ones_like(mask) - torch.eye(mask.size(0), device=mask.device)\n",
    "    mask = mask * logits_mask\n",
    "\n",
    "    exp_logits = torch.exp(logits) * logits_mask\n",
    "    log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-9)\n",
    "    mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-9)\n",
    "\n",
    "    loss = -mean_log_prob_pos.mean()\n",
    "    return loss\n",
    "\n",
    "# -------------------- Training Losses --------------------\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, weight=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        pt = torch.exp(logpt)\n",
    "        logpt = (1 - pt) ** self.gamma * logpt\n",
    "        loss = F.nll_loss(logpt, target, weight=self.weight, reduction=self.reduction)\n",
    "        return self.alpha * loss\n",
    "\n",
    "\n",
    "def dice_loss(logits, targets, smooth=1):\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    targets_one_hot = F.one_hot(targets, num_classes=logits.size(1)).float().to(logits.device)\n",
    "    intersection = (probs * targets_one_hot).sum(dim=0)\n",
    "    cardinality = probs.sum(dim=0) + targets_one_hot.sum(dim=0)\n",
    "    dice = (2. * intersection + smooth) / (cardinality + smooth)\n",
    "    return 1. - dice.mean()\n",
    "\n",
    "\n",
    "def smoothed_cross_entropy(logits, target, smoothing=0.1):\n",
    "    num_classes = logits.size(1)\n",
    "    confidence = 1.0 - smoothing\n",
    "    with torch.no_grad():\n",
    "        true_dist = torch.zeros_like(logits)\n",
    "        true_dist.fill_(smoothing / (num_classes - 1))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), confidence)\n",
    "    log_probs = F.log_softmax(logits, dim=1)\n",
    "    return torch.mean(torch.sum(-true_dist * log_probs, dim=1))\n",
    "\n",
    "\n",
    "# -------------------- Helper --------------------\n",
    "def get_preds_from_logits(logits):\n",
    "    \"\"\"Return predicted class indices and softmax probabilities.\"\"\"\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    preds = torch.argmax(probs, dim=-1)\n",
    "    return preds, probs\n",
    "\n",
    "\n",
    "def train_model_for_level(\n",
    "    num_labels, train_loader, val_loader, save_path, level_name=\"level\",\n",
    "    y_train_labels=None, loss_type=\"focal+dice\", contrastive_weight=0.2, label_smoothing=0.0\n",
    "):\n",
    "    # Ensure plot and log directories exist\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, \"plots\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, \"logs\"), exist_ok=True)\n",
    "\n",
    "    model = DebertaV2ForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels).to(device)\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model.config.output_hidden_states = True\n",
    "\n",
    "    # Compute class weights\n",
    "    if y_train_labels is not None:\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "    else:\n",
    "        all_train_labels = [label.item() for batch in train_loader for label in batch['labels']]\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(all_train_labels), y=all_train_labels)\n",
    "\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    focal = FocalLoss(weight=class_weights_tensor)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=EPOCHS * len(train_loader))\n",
    "\n",
    "    best_f1 = 0\n",
    "    patience_counter = 0\n",
    "    train_losses, train_accuracies, train_f1s = [], [], []\n",
    "    val_accuracies, val_f1s = [], []\n",
    "    best_metrics = {}\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"[{level_name}] Epoch {epoch+1}/{EPOCHS}\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # ===== Loss Calculation =====\n",
    "            loss = 0\n",
    "            if \"focal\" in loss_type:\n",
    "                loss += focal(logits, batch['labels'])\n",
    "            elif label_smoothing > 0:\n",
    "                loss += smoothed_cross_entropy(logits, batch['labels'], smoothing=label_smoothing)\n",
    "            else:\n",
    "                loss += F.cross_entropy(logits, batch['labels'], weight=class_weights_tensor)\n",
    "\n",
    "            if \"dice\" in loss_type:\n",
    "                loss += dice_loss(logits, batch['labels'])\n",
    "\n",
    "            if \"contrastive\" in loss_type:\n",
    "                hidden_states = outputs.hidden_states[-1][:, 0, :]\n",
    "                loss += contrastive_weight * apply_contrastive_supervision(hidden_states, batch['labels'])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds, _ = get_preds_from_logits(logits)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "        train_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        train_acc = accuracy_score(all_labels, all_preds)\n",
    "        train_losses.append(total_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        train_f1s.append(train_f1)\n",
    "\n",
    "        # ===== Validation =====\n",
    "        model.eval()\n",
    "        val_preds, val_labels, val_probs = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                logits = outputs.logits\n",
    "                preds, probs = get_preds_from_logits(logits)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(batch['labels'].cpu().numpy())\n",
    "                val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "        try:\n",
    "            val_labels_bin = label_binarize(val_labels, classes=list(range(num_labels)))\n",
    "            roc_auc = roc_auc_score(val_labels_bin, val_probs, average='macro', multi_class='ovr')\n",
    "        except Exception as e:\n",
    "            print(f\" ROC AUC calculation failed: {e}\")\n",
    "            roc_auc = None\n",
    "\n",
    "        print(f\" Epoch {epoch+1} | Loss: {total_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_f1s.append(val_f1)\n",
    "\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            patience_counter = 0\n",
    "\n",
    "            #  Save best checkpoint\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                torch.save(model.state_dict(), f)\n",
    "\n",
    "            precision, recall, f1_metric, _ = precision_recall_fscore_support(val_labels, val_preds, average='weighted')\n",
    "            best_metrics = {\n",
    "                \"val_precision_weighted\": precision,\n",
    "                \"val_recall_weighted\": recall,\n",
    "                \"val_f1_weighted\": f1_metric,\n",
    "                \"roc_auc\": roc_auc\n",
    "            }\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(\" Early stopping.\")\n",
    "                break\n",
    "\n",
    "    # ===== Plot Training Curve =====\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(train_f1s, label=\"Train F1\")\n",
    "    plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "    plt.plot(val_f1s, label=\"Val F1\")\n",
    "    plt.plot(val_accuracies, label=\"Val Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title(f\" Training Curve - {level_name}\")\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/plots/loss_f1_curve_{level_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # ===== Save Training Log =====\n",
    "    history = {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"train_accuracies\": train_accuracies,\n",
    "        \"train_f1s\": train_f1s,\n",
    "        \"val_f1s\": val_f1s,\n",
    "        \"val_accuracies\": val_accuracies,\n",
    "        **best_metrics\n",
    "    }\n",
    "    with open(f\"{OUTPUT_DIR}/logs/history_{level_name}.json\", \"w\") as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "\n",
    "    #  Return the best model (loaded from disk)\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Evaluation --------------------\n",
    "def evaluate_saved_model(model_path, dataloader, num_labels):\n",
    "    model = DebertaV2ForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds.extend(torch.argmax(outputs.logits, dim=-1).cpu().numpy())\n",
    "            labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "    report = classification_report(labels, preds, digits=4)\n",
    "    print(report)\n",
    "\n",
    "def load_model_for_inference(num_labels, path, device):\n",
    "    model = DebertaV2ForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def visualize_model_performance(true_labels, pred_labels, class_names, title, save_path):\n",
    "    \"\"\"\n",
    "    Visualizes classification performance using a confusion matrix and saves the classification report.\n",
    "\n",
    "    Args:\n",
    "        true_labels (list or np.array): Ground truth labels.\n",
    "        pred_labels (list or np.array): Predicted labels from the ensemble.\n",
    "        class_names (list): List of class label names (e.g., label_encoder.classes_).\n",
    "        title (str): Title for the plot and report.\n",
    "        save_path (str): Path to save the confusion matrix image.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(true_labels, pred_labels, target_names=class_names, digits=4)\n",
    "    print(report)\n",
    "\n",
    "    # Save report\n",
    "    report_path = save_path.replace(\".png\", \"_report.txt\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(true_labels, pred_labels, class_names, title, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2806399,
     "status": "ok",
     "timestamp": 1751099098271,
     "user": {
      "displayName": "RUSHI KANNAN",
      "userId": "14122798334208989020"
     },
     "user_tz": -330
    },
    "id": "f8wWY42eY1eg",
    "outputId": "489575cf-f0b6-4e40-c1fc-b6ed9a1c9951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Train size: 12859, Validation size: 1429\n",
      "ðŸ”Ž Train Source Distribution:\n",
      " source\n",
      "reddit     4500\n",
      "youtube    4500\n",
      "twitter    3859\n",
      "Name: count, dtype: int64\n",
      "ðŸ”Ž Validation Source Distribution:\n",
      " source\n",
      "reddit     500\n",
      "youtube    500\n",
      "twitter    429\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ“‚ Level 1 Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[level1_fold5] Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 643/643 [14:32<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Epoch 1 | Loss: 815.7788 | Train Acc: 0.7367 | Val Acc: 0.8044 | Train F1: 0.7459 | Val F1: 0.8076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level1_fold5] Epoch 2/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 643/643 [14:31<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Epoch 2 | Loss: 640.2732 | Train Acc: 0.8406 | Val Acc: 0.8285 | Train F1: 0.8456 | Val F1: 0.8317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level1_fold5] Epoch 3/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 643/643 [14:31<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Epoch 3 | Loss: 580.1549 | Train Acc: 0.8688 | Val Acc: 0.8312 | Train F1: 0.8724 | Val F1: 0.8360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1-1965011586.py:308: UserWarning: Glyph 128200 (\\N{CHART WITH UPWARDS TREND}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f\"{OUTPUT_DIR}/plots/loss_f1_curve_{level_name}.png\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch\n",
    "from transformers import DebertaV2Tokenizer\n",
    "from scipy.stats import mode\n",
    "\n",
    "# ==== Assumed Pre-defined: SEED, OUTPUT_DIR, BATCH_SIZE, VAL_BATCH_SIZE, CryptoDataset, collate_fn,\n",
    "# train_model_for_level, load_model_for_inference, visualize_model_performance ====\n",
    "\n",
    "# === FIXED PATH FOR LEVEL 1 ENCODER ===\n",
    "LEVEL1_ENCODER_PATH = \"/content/drive/MyDrive/FIRE/outputs/run_20250628_034630/encoders/label_encoder_level_1.pkl\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = os.path.join(OUTPUT_DIR, f\"run_{run_id}\")\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    for subfolder in [\"models\", \"plots\", \"logs\", \"encoders\", \"ensembles\"]:\n",
    "        os.makedirs(os.path.join(run_dir, subfolder), exist_ok=True)\n",
    "\n",
    "    # === Load Data ===\n",
    "    train_df = pd.read_csv(\"/content/drive/MyDrive/FIRE/crypto_task1_train.csv\")\n",
    "    val_df = pd.read_csv(\"/content/drive/MyDrive/FIRE/crypto_task1_val.csv\")\n",
    "\n",
    "    print(f\"\\n Train size: {len(train_df)}, Validation size: {len(val_df)}\")\n",
    "    print(\" Train Source Distribution:\\n\", train_df['source'].value_counts())\n",
    "    print(\"Validation Source Distribution:\\n\", val_df['source'].value_counts())\n",
    "\n",
    "    # === Add [SOURCE] token ===\n",
    "    def add_source_token(df):\n",
    "        df = df.copy()\n",
    "        df['source_token'] = df['source'].str.upper().map({\n",
    "            'REDDIT': '[REDDIT]',\n",
    "            'TWITTER': '[TWITTER]',\n",
    "            'YOUTUBE': '[YOUTUBE]'\n",
    "        })\n",
    "        df['text'] = df['source_token'] + ' ' + df['text']\n",
    "        return df\n",
    "\n",
    "    train_df = add_source_token(train_df)\n",
    "    val_df = add_source_token(val_df)\n",
    "\n",
    "    tokenizer = DebertaV2Tokenizer.from_pretrained(os.path.join(OUTPUT_DIR, \"tokenizer\"))\n",
    "\n",
    "    def save_ensemble_model(preds_list, save_path):\n",
    "        np.save(save_path, np.array(preds_list))\n",
    "\n",
    "    def save_platform_reports(val_sources, platforms, true_labels, majority_preds, label_classes, level_num):\n",
    "        for platform in platforms:\n",
    "            mask = val_sources == platform\n",
    "            platform_true = true_labels[mask]\n",
    "            platform_pred = majority_preds[mask]\n",
    "            report = classification_report(platform_true, platform_pred, target_names=label_classes, digits=4)\n",
    "            print(f\"\\n Level {level_num} - Platform: {platform}\")\n",
    "            print(report)\n",
    "            with open(f\"{run_dir}/logs/level{level_num}_report_{platform}.txt\", \"w\") as f:\n",
    "                f.write(report)\n",
    "\n",
    "    # -------- LEVEL 1 --------\n",
    "    # -------- LEVEL 1 --------\n",
    "le1 = LabelEncoder()\n",
    "train_df['level_1_enc'] = le1.fit_transform(train_df['level_1'])\n",
    "val_df['level_1_enc'] = le1.transform(val_df['level_1'])\n",
    "\n",
    "# Save label encoder to specified path\n",
    "pickle.dump(le1, open(\"/content/drive/MyDrive/FIRE/outputs/run_20250628_034630/encoders/label_encoder_level_1.pkl\", \"wb\"))\n",
    "\n",
    "skf1 = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf1.split(train_df, train_df['level_1_enc'])):\n",
    "    if fold != 4:\n",
    "        continue  #  Skip all folds except Fold 5\n",
    "\n",
    "    print(f\"\\n Level 1 Fold {fold + 1}/5\")\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    source_weights = train_fold_df['source'].map({\n",
    "        'YOUTUBE': 2.5,\n",
    "        'REDDIT': 2.5,\n",
    "        'TWITTER': 6.5\n",
    "    }).fillna(1.0).astype(float).values\n",
    "    source_weights = torch.tensor(source_weights, dtype=torch.double)\n",
    "    sampler = WeightedRandomSampler(source_weights, num_samples=len(source_weights), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        CryptoDataset(train_fold_df['text'], train_fold_df['level_1_enc'], tokenizer),\n",
    "        batch_size=BATCH_SIZE, sampler=sampler, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(\n",
    "        CryptoDataset(val_fold_df['text'], val_fold_df['level_1_enc'], tokenizer),\n",
    "        batch_size=VAL_BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    model_path = \"/content/drive/MyDrive/FIRE/outputs/run_20250628_034630/models/level1_fold5.pth\"\n",
    "    model = train_model_for_level(\n",
    "        num_labels=len(le1.classes_),\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        save_path=model_path,\n",
    "        level_name=\"level1_fold5\",\n",
    "        y_train_labels=train_fold_df['level_1_enc'],\n",
    "        loss_type=\"focal+dice+contrastive\",\n",
    "        label_smoothing=0.1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85742,
     "status": "ok",
     "timestamp": 1751099728264,
     "user": {
      "displayName": "RUSHI KANNAN",
      "userId": "14122798334208989020"
     },
     "user_tz": -330
    },
    "id": "k5SQplrKY5br",
    "outputId": "6d51b64f-65bc-45b4-f7eb-0dcc7dfa0c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Columns in validation CSV: ['text', 'level_1', 'level_2', 'level_3', 'source']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Fold 1 â€” loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Fold 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:05<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Fold 2 â€” loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Fold 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:05<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Fold 3 â€” loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Fold 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:05<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Fold 4 â€” loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Fold 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:05<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Fold 5 â€” loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Fold 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:05<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Ensemble Accuracy: 0.8383\n",
      "ðŸŽ¯ F1 (Weighted): 0.8424\n",
      "ðŸ“ F1 (Macro):    0.7832\n",
      "ðŸ“ F1 (Micro):    0.8383\n",
      "ðŸŽ¯ Precision (Macro): 0.7669\n",
      "ðŸ“Œ Recall (Macro):    0.8122\n",
      "\n",
      "ðŸ“‹ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7074    0.6871    0.6971       278\n",
      "           1     0.6457    0.8744    0.7429       223\n",
      "           2     0.9475    0.8750    0.9098       928\n",
      "\n",
      "    accuracy                         0.8383      1429\n",
      "   macro avg     0.7669    0.8122    0.7832      1429\n",
      "weighted avg     0.8537    0.8383    0.8424      1429\n",
      "\n",
      "\n",
      "\n",
      "ðŸ”Ž Platform-wise Evaluation:\n",
      "\n",
      "ðŸ“¦ Platform: YOUTUBE\n",
      "Accuracy: 0.9080\n",
      "F1 Weighted: 0.9077\n",
      "F1 Macro:    0.6915\n",
      "Platform Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7250    0.7342    0.7296        79\n",
      "           1     0.5000    0.3333    0.4000         3\n",
      "           2     0.9450    0.9450    0.9450       418\n",
      "\n",
      "    accuracy                         0.9080       500\n",
      "   macro avg     0.7233    0.6708    0.6915       500\n",
      "weighted avg     0.9075    0.9080    0.9077       500\n",
      "\n",
      "\n",
      "ðŸ“¦ Platform: REDDIT\n",
      "Accuracy: 0.8940\n",
      "F1 Weighted: 0.8971\n",
      "F1 Macro:    0.8159\n",
      "Platform Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7246    0.7692    0.7463        65\n",
      "           1     0.6825    0.8600    0.7611        50\n",
      "           2     0.9620    0.9195    0.9402       385\n",
      "\n",
      "    accuracy                         0.8940       500\n",
      "   macro avg     0.7897    0.8496    0.8159       500\n",
      "weighted avg     0.9032    0.8940    0.8971       500\n",
      "\n",
      "\n",
      "ðŸ“¦ Platform: TWITTER\n",
      "Accuracy: 0.6923\n",
      "F1 Weighted: 0.6847\n",
      "F1 Macro:    0.6786\n",
      "Platform Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6860    0.6194    0.6510       134\n",
      "           1     0.6371    0.8882    0.7420       170\n",
      "           2     0.8873    0.5040    0.6429       125\n",
      "\n",
      "    accuracy                         0.6923       429\n",
      "   macro avg     0.7368    0.6705    0.6786       429\n",
      "weighted avg     0.7253    0.6923    0.6847       429\n",
      "\n",
      "\n",
      "âœ… All outputs saved to: /content/drive/MyDrive/FIRE/outputs/ensemble_level1_eval\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from scipy.stats import mode\n",
    "from transformers import DebertaV2ForSequenceClassification, AutoTokenizer\n",
    "import pickle\n",
    "\n",
    "# === CONFIG ===\n",
    "model_paths = [\n",
    "    \"/content/drive/MyDrive/FIRE/outputs/run_20250628_034630/models/level1_fold1.pth\",\n",
    "    \"/content/drive/MyDrive/FIRE/outputs/run_20250628_034630/models/level1_fold2.pth\",\n",
    "    \"/content/drive/MyDrive/FIRE/outputs/run_20250628_034630/models/level1_fold3.pth\",\n",
    "    \"/content/drive/MyDrive/FIRE/outputs/run_20250628_034630/models/level1_fold4.pth\",\n",
    "    \"/content/drive/MyDrive/FIRE/outputs/run_20250628_034630/models/level1_fold5.pth\",\n",
    "]\n",
    "model_name = \"microsoft/deberta-v3-small\"\n",
    "label_encoder_path = \"/content/drive/MyDrive/FIRE/outputs/run_20250628_034630/encoders/label_encoder_level_1.pkl\"\n",
    "val_csv_path = \"/content/drive/MyDrive/FIRE/crypto_task1_val.csv\"\n",
    "save_dir = \"/content/drive/MyDrive/FIRE/outputs/ensemble_level1_eval\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# === Load label encoder ===\n",
    "with open(label_encoder_path, \"rb\") as f:\n",
    "    le1 = pickle.load(f)\n",
    "\n",
    "# === Load and preprocess validation data ===\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "print(\" Columns in validation CSV:\", val_df.columns.tolist())\n",
    "\n",
    "# Add [SOURCE] token to text\n",
    "val_df['source_token'] = val_df['source'].str.upper().map({\n",
    "    'REDDIT': '[REDDIT]',\n",
    "    'TWITTER': '[TWITTER]',\n",
    "    'YOUTUBE': '[YOUTUBE]'\n",
    "})\n",
    "val_df['text'] = val_df['source_token'] + ' ' + val_df['text']\n",
    "\n",
    "# Encode labels\n",
    "if 'level_1_enc' not in val_df.columns:\n",
    "    if 'level_1' in val_df.columns:\n",
    "        val_df['level_1_enc'] = le1.transform(val_df['level_1'])\n",
    "    else:\n",
    "        raise ValueError(\" 'level_1_enc' or 'level_1' must be present in CSV.\")\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "encodings = tokenizer(\n",
    "    list(val_df['text']),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "labels = torch.tensor(val_df['level_1_enc'].values)\n",
    "true_labels = labels.numpy()\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(\n",
    "    encodings['input_ids'], encodings['attention_mask'], labels\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# === Inference ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "all_fold_preds = []\n",
    "\n",
    "for fold, model_path in enumerate(model_paths):\n",
    "    print(f\"\\n Fold {fold+1} â€” loading model\")\n",
    "    model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=len(le1.classes_)\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Predicting Fold {fold+1}\"):\n",
    "            input_ids, attention_mask, _ = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            fold_preds.extend(preds)\n",
    "\n",
    "    all_fold_preds.append(np.array(fold_preds))\n",
    "\n",
    "# === Majority Voting ===\n",
    "ensemble_preds = mode(np.array(all_fold_preds), axis=0).mode.squeeze()\n",
    "pred_labels = le1.inverse_transform(ensemble_preds)\n",
    "\n",
    "# Save predictions\n",
    "val_df[\"preds\"] = ensemble_preds\n",
    "val_df[\"pred_labels\"] = pred_labels\n",
    "val_df.to_csv(os.path.join(save_dir, \"level1_val_predictions.csv\"), index=False)\n",
    "\n",
    "# === Overall Metrics ===\n",
    "acc = accuracy_score(true_labels, ensemble_preds)\n",
    "f1_weighted = f1_score(true_labels, ensemble_preds, average='weighted')\n",
    "f1_macro = f1_score(true_labels, ensemble_preds, average='macro')\n",
    "f1_micro = f1_score(true_labels, ensemble_preds, average='micro')\n",
    "prec_macro = precision_score(true_labels, ensemble_preds, average='macro')\n",
    "recall_macro = recall_score(true_labels, ensemble_preds, average='macro')\n",
    "\n",
    "try:\n",
    "    report = classification_report(\n",
    "        true_labels,\n",
    "        ensemble_preds,\n",
    "        labels=list(range(len(le1.classes_))),\n",
    "        target_names=[str(c) for c in le1.classes_],\n",
    "        digits=4\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\" Error generating classification report:\", e)\n",
    "    report = classification_report(true_labels, ensemble_preds, digits=4)\n",
    "\n",
    "metrics_text = f\"\"\"\n",
    " Ensemble Accuracy: {acc:.4f}\n",
    " F1 (Weighted): {f1_weighted:.4f}\n",
    " F1 (Macro):    {f1_macro:.4f}\n",
    " F1 (Micro):    {f1_micro:.4f}\n",
    " Precision (Macro): {prec_macro:.4f}\n",
    " Recall (Macro):    {recall_macro:.4f}\n",
    "\n",
    " Classification Report:\n",
    "{report}\n",
    "\"\"\"\n",
    "\n",
    "print(metrics_text)\n",
    "with open(os.path.join(save_dir, \"metrics.txt\"), \"w\") as f:\n",
    "    f.write(metrics_text)\n",
    "\n",
    "# === Confusion Matrix ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "cm = confusion_matrix(true_labels, ensemble_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix (Level 1 Ensemble)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"confusion_matrix.png\"))\n",
    "plt.close()\n",
    "\n",
    "# ===  Platform-wise Evaluation â€” using val_df['source'].str.lower()\n",
    "print(\"\\n Platform-wise Evaluation:\")\n",
    "platforms = [\"youtube\", \"reddit\", \"twitter\"]\n",
    "\n",
    "for platform in platforms:\n",
    "    mask = val_df['source'].str.lower() == platform\n",
    "    y_true = true_labels[mask]\n",
    "    y_pred = ensemble_preds[mask]\n",
    "\n",
    "    print(f\"\\n Platform: {platform.upper()}\")\n",
    "    if len(y_true) == 0:\n",
    "        print(f\" No samples for {platform.upper()}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Weighted: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"F1 Macro:    {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "\n",
    "    try:\n",
    "        platform_report = classification_report(\n",
    "            y_true, y_pred,\n",
    "            labels=list(range(len(le1.classes_))),\n",
    "            target_names=[str(c) for c in le1.classes_],\n",
    "            digits=4\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\" Error generating report:\", e)\n",
    "        platform_report = classification_report(y_true, y_pred, digits=4)\n",
    "\n",
    "    print(f\"Platform Report:\\n{platform_report}\")\n",
    "\n",
    "print(f\"\\n All outputs saved to: {save_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAKX263Y3a4NvnGwdxPivi",
   "mount_file_id": "1A_PwUKqvERjlflOXWBT8g_HKlSnxKoXX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02d2a68528d44bda96b17738e40766db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_89445f13c88e486fb5e5d2b9ade14506",
       "IPY_MODEL_8b728c1eccdb4e249f4b162e3d4e5b62",
       "IPY_MODEL_44723cd190604e36b94846e0bc768cab"
      ],
      "layout": "IPY_MODEL_a7f5bbe8d12c406f884945d99edcbad7"
     }
    },
    "05568fd1f3e84bc5b5c71054974f68b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cec8cefce724b29bcf40399a67dc1d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "15cf8c0a86e44c43801dd3a9ccee7733": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b045c92c5c44350948750c8f6c833a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd89f9d29fba442c87c7ff8032840c45",
       "IPY_MODEL_d13222378b4a4f74ac2e40e000180b8b",
       "IPY_MODEL_658e58175e984919a679871f6a83c570"
      ],
      "layout": "IPY_MODEL_40964608f6f24173aa405082626ec76f"
     }
    },
    "21908f165b754acbbaf74c358792812a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26d56c987acb4f7886c171a67e4f01f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2964fc1ecf47403b8159606a4545f80d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f6bedae5d7d4ea8bc0dbbc3b0a6284d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "40964608f6f24173aa405082626ec76f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44723cd190604e36b94846e0bc768cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_993fa1ab4ee94306a192542d7e56a619",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_de6f0a9be05f44f2aa28d3430711e314",
      "value": "â€‡578/578â€‡[00:00&lt;00:00,â€‡58.3kB/s]"
     }
    },
    "4fdfb6a9358a4cff9670eaa470af2492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d8192e375f24d8396c267292d4213e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "658e58175e984919a679871f6a83c570": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15cf8c0a86e44c43801dd3a9ccee7733",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2964fc1ecf47403b8159606a4545f80d",
      "value": "â€‡2.46M/2.46Mâ€‡[00:00&lt;00:00,â€‡20.3MB/s]"
     }
    },
    "6945d0bcf19b489fbdef85b678f70d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b333f29e60e540e291cd4a8b3c611eb6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4fdfb6a9358a4cff9670eaa470af2492",
      "value": "â€‡52.0/52.0â€‡[00:00&lt;00:00,â€‡5.26kB/s]"
     }
    },
    "7a8204f362964d5d923cbfa49dfdaa7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba69d252355f4dfbb83720c4fb37adef",
       "IPY_MODEL_e0735c4c6180424e90b999e84ed41439",
       "IPY_MODEL_6945d0bcf19b489fbdef85b678f70d90"
      ],
      "layout": "IPY_MODEL_b5df97ec6d304e54a8adba89f3847ca4"
     }
    },
    "89445f13c88e486fb5e5d2b9ade14506": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3ee64087d054ae79fcf90f2046dea20",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_21908f165b754acbbaf74c358792812a",
      "value": "config.json:â€‡100%"
     }
    },
    "8b728c1eccdb4e249f4b162e3d4e5b62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26d56c987acb4f7886c171a67e4f01f3",
      "max": 578,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b931439a66e34884be5bd75798ebc870",
      "value": 578
     }
    },
    "993fa1ab4ee94306a192542d7e56a619": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7f5bbe8d12c406f884945d99edcbad7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b333f29e60e540e291cd4a8b3c611eb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5df97ec6d304e54a8adba89f3847ca4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b931439a66e34884be5bd75798ebc870": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ba69d252355f4dfbb83720c4fb37adef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efd0cc34ffcd48a5966f7b723a540740",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bb7d161893e24d2a9a3fe0495f28005a",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "bb7d161893e24d2a9a3fe0495f28005a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3ee64087d054ae79fcf90f2046dea20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9aadc62f1c04a8b9c4f0ca3b70ab0bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d13222378b4a4f74ac2e40e000180b8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d8192e375f24d8396c267292d4213e6",
      "max": 2464616,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0cec8cefce724b29bcf40399a67dc1d8",
      "value": 2464616
     }
    },
    "de6ddcf364bd49348885bab3d93becaa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de6f0a9be05f44f2aa28d3430711e314": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0735c4c6180424e90b999e84ed41439": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05568fd1f3e84bc5b5c71054974f68b3",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f6bedae5d7d4ea8bc0dbbc3b0a6284d",
      "value": 52
     }
    },
    "efd0cc34ffcd48a5966f7b723a540740": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd89f9d29fba442c87c7ff8032840c45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de6ddcf364bd49348885bab3d93becaa",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c9aadc62f1c04a8b9c4f0ca3b70ab0bb",
      "value": "spm.model:â€‡100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
