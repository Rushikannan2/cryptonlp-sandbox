{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1CFON69rtweZx9gS_MlF-pvI4OCARmK1W","authorship_tag":"ABX9TyNrYZAjiqsEKa4HzdjACZqs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f12ce20f3c994c808fc499c3b59cdc80":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9df7d101ffeb4276acc37f47192fdaa1","IPY_MODEL_c6a0cf0626cd401e90d221adc74955d0","IPY_MODEL_370b6070880e45ae8cba50903198ced8"],"layout":"IPY_MODEL_1eafc55984704c6ea5730e3af6082f0b"}},"9df7d101ffeb4276acc37f47192fdaa1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fdd083fa19041d6b04c6c50b514749f","placeholder":"​","style":"IPY_MODEL_8242719ad2ca4f8a8c9bda1c8e7ed30c","value":"tokenizer_config.json: 100%"}},"c6a0cf0626cd401e90d221adc74955d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d35b4a9cad664247a2fe7446c381e9e0","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b5595a35ea1464aa4a2960c2c54d5a9","value":52}},"370b6070880e45ae8cba50903198ced8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6c1772cf8d142a38f4864f1c9886c1e","placeholder":"​","style":"IPY_MODEL_4e537ad4337d44e5a935f5b80afaf506","value":" 52.0/52.0 [00:00&lt;00:00, 2.22kB/s]"}},"1eafc55984704c6ea5730e3af6082f0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fdd083fa19041d6b04c6c50b514749f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8242719ad2ca4f8a8c9bda1c8e7ed30c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d35b4a9cad664247a2fe7446c381e9e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b5595a35ea1464aa4a2960c2c54d5a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6c1772cf8d142a38f4864f1c9886c1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e537ad4337d44e5a935f5b80afaf506":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa3e35b2c86d4b189f1214d72eb70943":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81ce83e768f547989cfa35b2dd557d71","IPY_MODEL_9266b040b4ad48e9a267ec4deee9c3bf","IPY_MODEL_416b90a7f60646d08f792c54bdeea6bc"],"layout":"IPY_MODEL_72e13e08850a4fe48d03502a801ccc9a"}},"81ce83e768f547989cfa35b2dd557d71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d1039d1a8fc462cb5dc9db818663834","placeholder":"​","style":"IPY_MODEL_bf5edb51d032462c9a18b229b855e5f5","value":"config.json: 100%"}},"9266b040b4ad48e9a267ec4deee9c3bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_027b4e914e0840b4bb49816407201db7","max":578,"min":0,"orientation":"horizontal","style":"IPY_MODEL_faca8ef9736448daa88663253a7bd513","value":578}},"416b90a7f60646d08f792c54bdeea6bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba127d0605c94d1fa58dadd780a4eadc","placeholder":"​","style":"IPY_MODEL_a901c045200d490799a76e65daf1f33c","value":" 578/578 [00:00&lt;00:00, 28.8kB/s]"}},"72e13e08850a4fe48d03502a801ccc9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d1039d1a8fc462cb5dc9db818663834":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf5edb51d032462c9a18b229b855e5f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"027b4e914e0840b4bb49816407201db7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"faca8ef9736448daa88663253a7bd513":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba127d0605c94d1fa58dadd780a4eadc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a901c045200d490799a76e65daf1f33c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f27c82f92491417a8a5324f64567cb37":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d523527dd5c4125bac676eb1d539ec5","IPY_MODEL_f7dfad2aa0fa490b96fe83b735f1aaf8","IPY_MODEL_531a055ecdf243da833eaade91a22412"],"layout":"IPY_MODEL_9695e3b8022d4f1599a0252ffa5b9fc7"}},"7d523527dd5c4125bac676eb1d539ec5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2717e6301f59407285b4179db9373767","placeholder":"​","style":"IPY_MODEL_d5419c51f7064ea292e847b5e91913af","value":"spm.model: 100%"}},"f7dfad2aa0fa490b96fe83b735f1aaf8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b60d4ffad99e4b43b9a12b866ca70e72","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_574a7a4c926e4a47a9bbf66c099fc459","value":2464616}},"531a055ecdf243da833eaade91a22412":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d4eef8b619a4e6e9839a39bd6c523bb","placeholder":"​","style":"IPY_MODEL_b55dbd7cffb94f73b72a40ee6a8d9bc1","value":" 2.46M/2.46M [00:00&lt;00:00, 90.8kB/s]"}},"9695e3b8022d4f1599a0252ffa5b9fc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2717e6301f59407285b4179db9373767":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5419c51f7064ea292e847b5e91913af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b60d4ffad99e4b43b9a12b866ca70e72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"574a7a4c926e4a47a9bbf66c099fc459":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d4eef8b619a4e6e9839a39bd6c523bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b55dbd7cffb94f73b72a40ee6a8d9bc1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b99e095b455e4c8d81aafce6c9fdf409":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_315206d902ac4e7ba116a9e910f8a30b","IPY_MODEL_9c17490e0bf6447a8cfafc5188a770da","IPY_MODEL_56f79c5ce10d40fea10dcd23748db91d"],"layout":"IPY_MODEL_dadc051fd81544b98c7d8de3eba99b6c"}},"315206d902ac4e7ba116a9e910f8a30b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de6b20efe0714470a61007417e926290","placeholder":"​","style":"IPY_MODEL_2b05fb0164f14beca6406a35337f0465","value":"pytorch_model.bin: 100%"}},"9c17490e0bf6447a8cfafc5188a770da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_090ebe8995f04bc29359cfd1237d9b57","max":286059269,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd59c7472bb44ac7880681a33c42cd49","value":286059269}},"56f79c5ce10d40fea10dcd23748db91d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40c4419796854d82a51c1f38170dc51c","placeholder":"​","style":"IPY_MODEL_c9a2f9491a5f4213beae431e0db78f53","value":" 286M/286M [00:02&lt;00:00, 150MB/s]"}},"dadc051fd81544b98c7d8de3eba99b6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de6b20efe0714470a61007417e926290":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b05fb0164f14beca6406a35337f0465":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"090ebe8995f04bc29359cfd1237d9b57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd59c7472bb44ac7880681a33c42cd49":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40c4419796854d82a51c1f38170dc51c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9a2f9491a5f4213beae431e0db78f53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6761cdf2d314921b8834f991cda0760":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb93a9a5e5fb4c308ea199ef03cba054","IPY_MODEL_4b1113a526e1407c8b76692051c02a1e","IPY_MODEL_bd89ac42ab4041ebbda74a9829d2925a"],"layout":"IPY_MODEL_2409e4ad1c7f4ba887d3976177967724"}},"bb93a9a5e5fb4c308ea199ef03cba054":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_274a9a95f20547b49c56321b6d8271b0","placeholder":"​","style":"IPY_MODEL_f44d98736cd944bbb0e76a47ce4b6db5","value":"model.safetensors: 100%"}},"4b1113a526e1407c8b76692051c02a1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95e25db06af74ab39b99f9d80019a3ca","max":286034994,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43eba215261a4844aac489ed815616aa","value":286034994}},"bd89ac42ab4041ebbda74a9829d2925a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc2c63d20ee54c91ac3a689ed37ba981","placeholder":"​","style":"IPY_MODEL_2313cc692e9844db97ba4efd5dccc74c","value":" 286M/286M [00:04&lt;00:00, 71.0MB/s]"}},"2409e4ad1c7f4ba887d3976177967724":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"274a9a95f20547b49c56321b6d8271b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f44d98736cd944bbb0e76a47ce4b6db5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95e25db06af74ab39b99f9d80019a3ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43eba215261a4844aac489ed815616aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc2c63d20ee54c91ac3a689ed37ba981":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2313cc692e9844db97ba4efd5dccc74c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# **LEEVL1**"],"metadata":{"id":"FYiz2BzQPl7P"}},{"cell_type":"code","source":["import os\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","from sklearn.metrics import (\n","    classification_report,\n","    confusion_matrix,\n","    accuracy_score,\n","    f1_score,\n","    precision_score,\n","    recall_score\n",")\n","from scipy.stats import mode\n","from transformers import DebertaV2ForSequenceClassification, AutoTokenizer\n","import pickle\n","\n","# === CONFIG ===\n","model_paths = [\n","    \"/content/drive/MyDrive/FIRE/run_20250628_034630/models/level1_fold1.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250628_034630/models/level1_fold2.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250628_034630/models/level1_fold3.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250628_034630/models/level1_fold4.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250628_034630/models/level1_fold5.pth\",\n","]\n","model_name = \"microsoft/deberta-v3-small\"\n","label_encoder_path = \"/content/drive/MyDrive/FIRE/run_20250628_034630/encoders/label_encoder_level_1.pkl\"\n","val_csv_path = \"/content/drive/MyDrive/FIRE/crypto_task1_val.csv\"\n","save_dir = \"/content/drive/MyDrive/FIRE/outputs/ensemble_level1_eval\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# === Load label encoder ===\n","with open(label_encoder_path, \"rb\") as f:\n","    le1 = pickle.load(f)\n","\n","# === Load and preprocess validation data ===\n","val_df = pd.read_csv(val_csv_path)\n","print(\" Columns in validation CSV:\", val_df.columns.tolist())\n","\n","# Add [SOURCE] token to text\n","val_df['source_token'] = val_df['source'].str.upper().map({\n","    'REDDIT': '[REDDIT]',\n","    'TWITTER': '[TWITTER]',\n","    'YOUTUBE': '[YOUTUBE]'\n","})\n","val_df['text'] = val_df['source_token'] + ' ' + val_df['text']\n","\n","# Encode labels\n","if 'level_1_enc' not in val_df.columns:\n","    if 'level_1' in val_df.columns:\n","        val_df['level_1_enc'] = le1.transform(val_df['level_1'])\n","    else:\n","        raise ValueError(\" 'level_1_enc' or 'level_1' must be present in CSV.\")\n","\n","# Tokenize\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","encodings = tokenizer(\n","    list(val_df['text']),\n","    padding=True,\n","    truncation=True,\n","    return_tensors='pt',\n","    max_length=128\n",")\n","\n","labels = torch.tensor(val_df['level_1_enc'].values)\n","true_labels = labels.numpy()\n","\n","val_dataset = torch.utils.data.TensorDataset(\n","    encodings['input_ids'], encodings['attention_mask'], labels\n",")\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n","\n","# === Inference ===\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","all_fold_preds = []\n","\n","for fold, model_path in enumerate(model_paths):\n","    print(f\"\\n Fold {fold+1} — loading model\")\n","    model = DebertaV2ForSequenceClassification.from_pretrained(\n","        model_name, num_labels=len(le1.classes_)\n","    )\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.to(device)\n","    model.eval()\n","\n","    fold_preds = []\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc=f\"Predicting Fold {fold+1}\"):\n","            input_ids, attention_mask, _ = [b.to(device) for b in batch]\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n","            fold_preds.extend(preds)\n","\n","    all_fold_preds.append(np.array(fold_preds))\n","\n","# === Majority Voting ===\n","ensemble_preds = mode(np.array(all_fold_preds), axis=0).mode.squeeze()\n","pred_labels = le1.inverse_transform(ensemble_preds)\n","\n","# Save predictions\n","val_df[\"preds\"] = ensemble_preds\n","val_df[\"pred_labels\"] = pred_labels\n","val_df.to_csv(os.path.join(save_dir, \"level1_val_predictions.csv\"), index=False)\n","\n","# === Overall Metrics ===\n","acc = accuracy_score(true_labels, ensemble_preds)\n","f1_weighted = f1_score(true_labels, ensemble_preds, average='weighted')\n","f1_macro = f1_score(true_labels, ensemble_preds, average='macro')\n","f1_micro = f1_score(true_labels, ensemble_preds, average='micro')\n","prec_macro = precision_score(true_labels, ensemble_preds, average='macro')\n","recall_macro = recall_score(true_labels, ensemble_preds, average='macro')\n","\n","try:\n","    report = classification_report(\n","        true_labels,\n","        ensemble_preds,\n","        labels=list(range(len(le1.classes_))),\n","        target_names=[str(c) for c in le1.classes_],\n","        digits=4\n","    )\n","except Exception as e:\n","    print(\" Error generating classification report:\", e)\n","    report = classification_report(true_labels, ensemble_preds, digits=4)\n","\n","metrics_text = f\"\"\"\n"," Ensemble Accuracy: {acc:.4f}\n"," F1 (Weighted): {f1_weighted:.4f}\n"," F1 (Macro):    {f1_macro:.4f}\n"," F1 (Micro):    {f1_micro:.4f}\n"," Precision (Macro): {prec_macro:.4f}\n"," Recall (Macro):    {recall_macro:.4f}\n","\n"," Classification Report:\n","{report}\n","\"\"\"\n","\n","print(metrics_text)\n","with open(os.path.join(save_dir, \"metrics.txt\"), \"w\") as f:\n","    f.write(metrics_text)\n","\n","# === Confusion Matrix ===\n","plt.figure(figsize=(6, 5))\n","cm = confusion_matrix(true_labels, ensemble_preds)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.title(\"Confusion Matrix (Level 1 Ensemble)\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(save_dir, \"confusion_matrix.png\"))\n","plt.close()\n","\n","# ===  Platform-wise Evaluation — using val_df['source'].str.lower()\n","print(\"\\n Platform-wise Evaluation:\")\n","platforms = [\"youtube\", \"reddit\", \"twitter\"]\n","\n","for platform in platforms:\n","    mask = val_df['source'].str.lower() == platform\n","    y_true = true_labels[mask]\n","    y_pred = ensemble_preds[mask]\n","\n","    print(f\"\\n Platform: {platform.upper()}\")\n","    if len(y_true) == 0:\n","        print(f\" No samples for {platform.upper()}. Skipping.\")\n","        continue\n","\n","    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n","    print(f\"F1 Weighted: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n","    print(f\"F1 Macro:    {f1_score(y_true, y_pred, average='macro'):.4f}\")\n","\n","    try:\n","        platform_report = classification_report(\n","            y_true, y_pred,\n","            labels=list(range(len(le1.classes_))),\n","            target_names=[str(c) for c in le1.classes_],\n","            digits=4\n","        )\n","    except Exception as e:\n","        print(\" Error generating report:\", e)\n","        platform_report = classification_report(y_true, y_pred, digits=4)\n","\n","    print(f\"Platform Report:\\n{platform_report}\")\n","\n","print(f\"\\n All outputs saved to: {save_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f12ce20f3c994c808fc499c3b59cdc80","9df7d101ffeb4276acc37f47192fdaa1","c6a0cf0626cd401e90d221adc74955d0","370b6070880e45ae8cba50903198ced8","1eafc55984704c6ea5730e3af6082f0b","9fdd083fa19041d6b04c6c50b514749f","8242719ad2ca4f8a8c9bda1c8e7ed30c","d35b4a9cad664247a2fe7446c381e9e0","8b5595a35ea1464aa4a2960c2c54d5a9","b6c1772cf8d142a38f4864f1c9886c1e","4e537ad4337d44e5a935f5b80afaf506","fa3e35b2c86d4b189f1214d72eb70943","81ce83e768f547989cfa35b2dd557d71","9266b040b4ad48e9a267ec4deee9c3bf","416b90a7f60646d08f792c54bdeea6bc","72e13e08850a4fe48d03502a801ccc9a","7d1039d1a8fc462cb5dc9db818663834","bf5edb51d032462c9a18b229b855e5f5","027b4e914e0840b4bb49816407201db7","faca8ef9736448daa88663253a7bd513","ba127d0605c94d1fa58dadd780a4eadc","a901c045200d490799a76e65daf1f33c","f27c82f92491417a8a5324f64567cb37","7d523527dd5c4125bac676eb1d539ec5","f7dfad2aa0fa490b96fe83b735f1aaf8","531a055ecdf243da833eaade91a22412","9695e3b8022d4f1599a0252ffa5b9fc7","2717e6301f59407285b4179db9373767","d5419c51f7064ea292e847b5e91913af","b60d4ffad99e4b43b9a12b866ca70e72","574a7a4c926e4a47a9bbf66c099fc459","6d4eef8b619a4e6e9839a39bd6c523bb","b55dbd7cffb94f73b72a40ee6a8d9bc1","b99e095b455e4c8d81aafce6c9fdf409","315206d902ac4e7ba116a9e910f8a30b","9c17490e0bf6447a8cfafc5188a770da","56f79c5ce10d40fea10dcd23748db91d","dadc051fd81544b98c7d8de3eba99b6c","de6b20efe0714470a61007417e926290","2b05fb0164f14beca6406a35337f0465","090ebe8995f04bc29359cfd1237d9b57","bd59c7472bb44ac7880681a33c42cd49","40c4419796854d82a51c1f38170dc51c","c9a2f9491a5f4213beae431e0db78f53","e6761cdf2d314921b8834f991cda0760","bb93a9a5e5fb4c308ea199ef03cba054","4b1113a526e1407c8b76692051c02a1e","bd89ac42ab4041ebbda74a9829d2925a","2409e4ad1c7f4ba887d3976177967724","274a9a95f20547b49c56321b6d8271b0","f44d98736cd944bbb0e76a47ce4b6db5","95e25db06af74ab39b99f9d80019a3ca","43eba215261a4844aac489ed815616aa","bc2c63d20ee54c91ac3a689ed37ba981","2313cc692e9844db97ba4efd5dccc74c"]},"id":"P5_Xx-dOPk46","executionInfo":{"status":"ok","timestamp":1752121893837,"user_tz":-330,"elapsed":157285,"user":{"displayName":"V T Rushi Kannan","userId":"06041568400969842982"}},"outputId":"bfe8a341-c075-4eed-af0a-0f1ef7921e1e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":[" Columns in validation CSV: ['text', 'level_1', 'level_2', 'level_3', 'source']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f12ce20f3c994c808fc499c3b59cdc80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa3e35b2c86d4b189f1214d72eb70943"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f27c82f92491417a8a5324f64567cb37"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Fold 1 — loading model\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b99e095b455e4c8d81aafce6c9fdf409"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/286M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6761cdf2d314921b8834f991cda0760"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Predicting Fold 1: 100%|██████████| 45/45 [00:06<00:00,  6.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Fold 2 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 2: 100%|██████████| 45/45 [00:05<00:00,  7.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Fold 3 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 3: 100%|██████████| 45/45 [00:06<00:00,  7.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Fold 4 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 4: 100%|██████████| 45/45 [00:06<00:00,  7.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Fold 5 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 5: 100%|██████████| 45/45 [00:06<00:00,  7.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Ensemble Accuracy: 0.8383\n"," F1 (Weighted): 0.8424\n"," F1 (Macro):    0.7832\n"," F1 (Micro):    0.8383\n"," Precision (Macro): 0.7669\n"," Recall (Macro):    0.8122\n","\n"," Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.7074    0.6871    0.6971       278\n","           1     0.6457    0.8744    0.7429       223\n","           2     0.9475    0.8750    0.9098       928\n","\n","    accuracy                         0.8383      1429\n","   macro avg     0.7669    0.8122    0.7832      1429\n","weighted avg     0.8537    0.8383    0.8424      1429\n","\n","\n","\n"," Platform-wise Evaluation:\n","\n"," Platform: YOUTUBE\n","Accuracy: 0.9080\n","F1 Weighted: 0.9077\n","F1 Macro:    0.6915\n","Platform Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.7250    0.7342    0.7296        79\n","           1     0.5000    0.3333    0.4000         3\n","           2     0.9450    0.9450    0.9450       418\n","\n","    accuracy                         0.9080       500\n","   macro avg     0.7233    0.6708    0.6915       500\n","weighted avg     0.9075    0.9080    0.9077       500\n","\n","\n"," Platform: REDDIT\n","Accuracy: 0.8940\n","F1 Weighted: 0.8971\n","F1 Macro:    0.8159\n","Platform Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.7246    0.7692    0.7463        65\n","           1     0.6825    0.8600    0.7611        50\n","           2     0.9620    0.9195    0.9402       385\n","\n","    accuracy                         0.8940       500\n","   macro avg     0.7897    0.8496    0.8159       500\n","weighted avg     0.9032    0.8940    0.8971       500\n","\n","\n"," Platform: TWITTER\n","Accuracy: 0.6923\n","F1 Weighted: 0.6847\n","F1 Macro:    0.6786\n","Platform Report:\n","              precision    recall  f1-score   support\n","\n","           0     0.6860    0.6194    0.6510       134\n","           1     0.6371    0.8882    0.7420       170\n","           2     0.8873    0.5040    0.6429       125\n","\n","    accuracy                         0.6923       429\n","   macro avg     0.7368    0.6705    0.6786       429\n","weighted avg     0.7253    0.6923    0.6847       429\n","\n","\n"," All outputs saved to: /content/drive/MyDrive/FIRE/outputs/ensemble_level1_eval\n"]}]},{"cell_type":"markdown","source":["**LEVEL2**"],"metadata":{"id":"_Y_41HvgNkHt"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hOCIxN4U_OwM","executionInfo":{"status":"ok","timestamp":1752122035206,"user_tz":-330,"elapsed":101492,"user":{"displayName":"V T Rushi Kannan","userId":"06041568400969842982"}},"outputId":"bdcfea48-e148-4d96-8d4f-5172580799a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in validation CSV: ['text', 'level_1', 'level_2', 'level_3', 'source']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold 1 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 1: 100%|██████████| 29/29 [00:04<00:00,  7.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold 2 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 2: 100%|██████████| 29/29 [00:04<00:00,  7.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold 3 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 3: 100%|██████████| 29/29 [00:04<00:00,  7.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold 4 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 4: 100%|██████████| 29/29 [00:03<00:00,  7.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold 5 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 5: 100%|██████████| 29/29 [00:03<00:00,  7.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Ensemble Accuracy: 0.8190\n","F1 (Weighted): 0.8001\n","F1 (Macro):    0.6440\n","F1 (Micro):    0.8190\n","Precision (Macro): 0.7272\n","Recall (Macro):    0.6103\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","         0.0     0.8363    0.9545    0.8915       637\n","         1.0     0.8049    0.6439    0.7154       205\n","         2.0     0.5405    0.2326    0.3252        86\n","\n","    accuracy                         0.8190       928\n","   macro avg     0.7272    0.6103    0.6440       928\n","weighted avg     0.8020    0.8190    0.8001       928\n","\n","\n","\n","Platform-wise Evaluation:\n","\n","Platform: YOUTUBE\n","Accuracy: 0.8254\n","F1 Weighted: 0.8154\n","F1 Macro:    0.6098\n","Platform Report:\n","              precision    recall  f1-score   support\n","\n","         0.0     0.8204    0.9510    0.8809       245\n","         1.0     0.8730    0.6962    0.7746       158\n","         2.0     0.2500    0.1333    0.1739        15\n","\n","    accuracy                         0.8254       418\n","   macro avg     0.6478    0.5935    0.6098       418\n","weighted avg     0.8198    0.8254    0.8154       418\n","\n","\n","Platform: REDDIT\n","Accuracy: 0.8338\n","F1 Weighted: 0.8102\n","F1 Macro:    0.5546\n","Platform Report:\n","              precision    recall  f1-score   support\n","\n","         0.0     0.8728    0.9609    0.9147       307\n","         1.0     0.6176    0.4667    0.5316        45\n","         2.0     0.3846    0.1515    0.2174        33\n","\n","    accuracy                         0.8338       385\n","   macro avg     0.6250    0.5264    0.5546       385\n","weighted avg     0.8011    0.8338    0.8102       385\n","\n","\n","Platform: TWITTER\n","Accuracy: 0.7520\n","F1 Weighted: 0.7243\n","F1 Macro:    0.5523\n","Platform Report:\n","              precision    recall  f1-score   support\n","\n","         0.0     0.7619    0.9412    0.8421        85\n","         1.0     0.2500    0.5000    0.3333         2\n","         2.0     0.8125    0.3421    0.4815        38\n","\n","    accuracy                         0.7520       125\n","   macro avg     0.6081    0.5944    0.5523       125\n","weighted avg     0.7691    0.7520    0.7243       125\n","\n","\n","All outputs saved to: /content/drive/MyDrive/FIRE/outputs/ensemble_level2_eval\n"]}],"source":["import os\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","from sklearn.metrics import (\n","    classification_report,\n","    confusion_matrix,\n","    accuracy_score,\n","    f1_score,\n","    precision_score,\n","    recall_score\n",")\n","from scipy.stats import mode\n","from transformers import DebertaV2ForSequenceClassification, AutoTokenizer\n","import pickle\n","\n","# === CONFIG ===\n","model_paths = [\n","    \"/content/drive/MyDrive/FIRE/run_20250629_090953/models/level2_fold1.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250629_090953/models/level2_fold2.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250629_090953/models/level2_fold3.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250629_090953/models/level2_fold4.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250629_090953/models/level2_fold5.pth\",\n","]\n","model_name = \"microsoft/deberta-v3-small\"\n","label_encoder_path = \"/content/drive/MyDrive/FIRE/run_20250629_090953/encoders/label_encoder_level_2.pkl\"\n","val_csv_path = \"/content/drive/MyDrive/FIRE/crypto_task1_val.csv\"\n","save_dir = \"/content/drive/MyDrive/FIRE/outputs/ensemble_level2_eval\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# === Load label encoder ===\n","with open(label_encoder_path, \"rb\") as f:\n","    le2 = pickle.load(f)\n","\n","# === Load and preprocess validation data ===\n","val_df = pd.read_csv(val_csv_path)\n","print(\"Columns in validation CSV:\", val_df.columns.tolist())\n","\n","# Add [SOURCE] token to text\n","val_df['source_token'] = val_df['source'].str.upper().map({\n","    'REDDIT': '[REDDIT]',\n","    'TWITTER': '[TWITTER]',\n","    'YOUTUBE': '[YOUTUBE]'\n","})\n","val_df['text'] = val_df['source_token'] + ' ' + val_df['text']\n","\n","# Only SUBJECTIVE samples are relevant for Level 2\n","subjective_mask = val_df['level_1'] == 2\n","val_df = val_df[subjective_mask].copy()\n","val_df[\"level_2_enc\"] = le2.transform(val_df[\"level_2\"])\n","true_labels = val_df[\"level_2_enc\"].values\n","\n","# Tokenize\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","encodings = tokenizer(\n","    list(val_df['text']),\n","    padding=True,\n","    truncation=True,\n","    return_tensors='pt',\n","    max_length=128\n",")\n","\n","labels = torch.tensor(true_labels)\n","val_dataset = torch.utils.data.TensorDataset(\n","    encodings['input_ids'], encodings['attention_mask'], labels\n",")\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n","\n","# === Inference ===\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","all_fold_preds = []\n","\n","for fold, model_path in enumerate(model_paths):\n","    print(f\"\\nFold {fold+1} — loading model\")\n","    model = DebertaV2ForSequenceClassification.from_pretrained(\n","        model_name, num_labels=len(le2.classes_)\n","    )\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.to(device)\n","    model.eval()\n","\n","    fold_preds = []\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc=f\"Predicting Fold {fold+1}\"):\n","            input_ids, attention_mask, _ = [b.to(device) for b in batch]\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n","            fold_preds.extend(preds)\n","\n","    all_fold_preds.append(np.array(fold_preds))\n","\n","# === Majority Voting ===\n","ensemble_preds = mode(np.array(all_fold_preds), axis=0).mode.squeeze()\n","pred_labels = le2.inverse_transform(ensemble_preds)\n","\n","# Save predictions\n","val_df[\"preds\"] = ensemble_preds\n","val_df[\"pred_labels\"] = pred_labels\n","val_df.to_csv(os.path.join(save_dir, \"level2_val_predictions.csv\"), index=False)\n","\n","# === Overall Metrics ===\n","acc = accuracy_score(true_labels, ensemble_preds)\n","f1_weighted = f1_score(true_labels, ensemble_preds, average='weighted')\n","f1_macro = f1_score(true_labels, ensemble_preds, average='macro')\n","f1_micro = f1_score(true_labels, ensemble_preds, average='micro')\n","prec_macro = precision_score(true_labels, ensemble_preds, average='macro')\n","recall_macro = recall_score(true_labels, ensemble_preds, average='macro')\n","\n","try:\n","    report = classification_report(\n","        true_labels,\n","        ensemble_preds,\n","        labels=list(range(len(le2.classes_))),\n","        target_names=[str(c) for c in le2.classes_],\n","        digits=4\n","    )\n","except Exception as e:\n","    print(\"Error generating classification report:\", e)\n","    report = classification_report(true_labels, ensemble_preds, digits=4)\n","\n","metrics_text = f\"\"\"\n","Ensemble Accuracy: {acc:.4f}\n","F1 (Weighted): {f1_weighted:.4f}\n","F1 (Macro):    {f1_macro:.4f}\n","F1 (Micro):    {f1_micro:.4f}\n","Precision (Macro): {prec_macro:.4f}\n","Recall (Macro):    {recall_macro:.4f}\n","\n","Classification Report:\n","{report}\n","\"\"\"\n","\n","print(metrics_text)\n","with open(os.path.join(save_dir, \"metrics.txt\"), \"w\") as f:\n","    f.write(metrics_text)\n","\n","# === Confusion Matrix ===\n","plt.figure(figsize=(6, 5))\n","cm = confusion_matrix(true_labels, ensemble_preds)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.title(\"Confusion Matrix (Level 2 Ensemble)\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(save_dir, \"confusion_matrix.png\"))\n","plt.close()\n","\n","# === Platform-wise Evaluation ===\n","print(\"\\nPlatform-wise Evaluation:\")\n","platforms = [\"youtube\", \"reddit\", \"twitter\"]\n","\n","for platform in platforms:\n","    mask = val_df['source'].str.lower() == platform\n","    y_true = val_df[\"level_2_enc\"].values[mask]\n","    y_pred = val_df[\"preds\"].values[mask]\n","\n","    print(f\"\\nPlatform: {platform.upper()}\")\n","    if len(y_true) == 0:\n","        print(f\"No samples for {platform.upper()}. Skipping.\")\n","        continue\n","\n","    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n","    print(f\"F1 Weighted: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n","    print(f\"F1 Macro:    {f1_score(y_true, y_pred, average='macro'):.4f}\")\n","\n","    try:\n","        platform_report = classification_report(\n","            y_true, y_pred,\n","            labels=list(range(len(le2.classes_))),\n","            target_names=[str(c) for c in le2.classes_],\n","            digits=4\n","        )\n","    except Exception as e:\n","        print(\"Error generating report:\", e)\n","        platform_report = classification_report(y_true, y_pred, digits=4)\n","\n","    print(f\"Platform Report:\\n{platform_report}\")\n","\n","print(f\"\\nAll outputs saved to: {save_dir}\")\n"]},{"cell_type":"markdown","source":["# **LEVEL3**"],"metadata":{"id":"6SvYm0JNNoiJ"}},{"cell_type":"code","source":["# === CONFIRMED LEVEL 3 INFERENCE & EVALUATION SCRIPT ===\n","import os\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","from sklearn.metrics import (\n","    classification_report,\n","    confusion_matrix,\n","    accuracy_score,\n","    f1_score,\n","    precision_score,\n","    recall_score\n",")\n","from scipy.stats import mode\n","from transformers import DebertaV2ForSequenceClassification, AutoTokenizer\n","import pickle\n","\n","# === CONFIG ===\n","model_paths = [\n","    \"/content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold1.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold2.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold3.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold4.pth\",\n","    \"/content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold5.pth\",\n","]\n","model_name = \"microsoft/deberta-v3-small\"\n","label_encoder_path = \"/content/drive/MyDrive/FIRE/run_20250629_121221/encoders/label_encoder_level_3.pkl\"\n","val_csv_path = \"/content/drive/MyDrive/FIRE/crypto_task1_val.csv\"\n","save_dir = \"/content/drive/MyDrive/FIRE/outputs/ensemble_level3_eval\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# === Load label encoder ===\n","with open(label_encoder_path, \"rb\") as f:\n","    le3 = pickle.load(f)\n","\n","# === Load and preprocess validation data ===\n","val_df = pd.read_csv(val_csv_path)\n","print(\"Columns in validation CSV:\", val_df.columns.tolist())\n","\n","val_df['source_token'] = val_df['source'].str.upper().map({\n","    'REDDIT': '[REDDIT]',\n","    'TWITTER': '[TWITTER]',\n","    'YOUTUBE': '[YOUTUBE]'\n","})\n","val_df['text'] = val_df['source_token'] + ' ' + val_df['text']\n","\n","# Only NEUTRAL under SUBJECTIVE are valid for Level 3\n","val_df = val_df[(val_df['level_1'] == 2) & (val_df['level_2'] == 0)].copy()\n","val_df[\"level_3_enc\"] = le3.transform(val_df[\"level_3\"])\n","true_labels = val_df[\"level_3_enc\"].values\n","\n","# Tokenize\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","encodings = tokenizer(\n","    list(val_df['text']),\n","    padding=True,\n","    truncation=True,\n","    return_tensors='pt',\n","    max_length=128\n",")\n","\n","labels = torch.tensor(true_labels)\n","val_dataset = torch.utils.data.TensorDataset(\n","    encodings['input_ids'], encodings['attention_mask'], labels\n",")\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n","\n","# === Inference ===\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","all_fold_preds = []\n","\n","for fold, model_path in enumerate(model_paths):\n","    print(f\"\\nFold {fold+1} — loading model\")\n","    model = DebertaV2ForSequenceClassification.from_pretrained(\n","        model_name, num_labels=len(le3.classes_)\n","    )\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.to(device)\n","    model.eval()\n","\n","    fold_preds = []\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc=f\"Predicting Fold {fold+1}\"):\n","            input_ids, attention_mask, _ = [b.to(device) for b in batch]\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n","            fold_preds.extend(preds)\n","\n","    all_fold_preds.append(np.array(fold_preds))\n","\n","# === Majority Voting ===\n","ensemble_preds = mode(np.array(all_fold_preds), axis=0).mode.squeeze()\n","pred_labels = le3.inverse_transform(ensemble_preds)\n","\n","# Save predictions\n","val_df[\"preds\"] = ensemble_preds\n","val_df[\"pred_labels\"] = pred_labels\n","val_df.to_csv(os.path.join(save_dir, \"level3_val_predictions.csv\"), index=False)\n","\n","# === Overall Metrics ===\n","acc = accuracy_score(true_labels, ensemble_preds)\n","f1_weighted = f1_score(true_labels, ensemble_preds, average='weighted')\n","f1_macro = f1_score(true_labels, ensemble_preds, average='macro')\n","f1_micro = f1_score(true_labels, ensemble_preds, average='micro')\n","prec_macro = precision_score(true_labels, ensemble_preds, average='macro')\n","recall_macro = recall_score(true_labels, ensemble_preds, average='macro')\n","\n","try:\n","    report = classification_report(\n","        true_labels,\n","        ensemble_preds,\n","        labels=list(range(len(le3.classes_))),\n","        target_names=[str(c) for c in le3.classes_],\n","        digits=4\n","    )\n","except Exception as e:\n","    print(\"Error generating classification report:\", e)\n","    report = classification_report(true_labels, ensemble_preds, digits=4)\n","\n","metrics_text = f\"\"\"\n","Ensemble Accuracy: {acc:.4f}\n","F1 (Weighted): {f1_weighted:.4f}\n","F1 (Macro):    {f1_macro:.4f}\n","F1 (Micro):    {f1_micro:.4f}\n","Precision (Macro): {prec_macro:.4f}\n","Recall (Macro):    {recall_macro:.4f}\n","\n","Classification Report:\n","{report}\n","\"\"\"\n","\n","print(metrics_text)\n","with open(os.path.join(save_dir, \"metrics.txt\"), \"w\") as f:\n","    f.write(metrics_text)\n","\n","# === Confusion Matrix ===\n","plt.figure(figsize=(6, 5))\n","cm = confusion_matrix(true_labels, ensemble_preds)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.title(\"Confusion Matrix (Level 3 Ensemble)\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(save_dir, \"confusion_matrix.png\"))\n","plt.close()\n","\n","# === Platform-wise Evaluation\n","print(\"\\nPlatform-wise Evaluation:\")\n","platforms = [\"youtube\", \"reddit\", \"twitter\"]\n","\n","for platform in platforms:\n","    mask = val_df['source'].str.lower() == platform\n","    y_true = val_df[\"level_3_enc\"].values[mask]\n","    y_pred = val_df[\"preds\"].values[mask]\n","\n","    print(f\"\\nPlatform: {platform.upper()}\")\n","    if len(y_true) == 0:\n","        print(f\"No samples for {platform.upper()}. Skipping.\")\n","        continue\n","\n","    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n","    print(f\"F1 Weighted: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n","    print(f\"F1 Macro:    {f1_score(y_true, y_pred, average='macro'):.4f}\")\n","\n","    try:\n","        platform_report = classification_report(\n","            y_true, y_pred,\n","            labels=list(range(len(le3.classes_))),\n","            target_names=[str(c) for c in le3.classes_],\n","            digits=4\n","        )\n","    except Exception as e:\n","        print(\"Error generating report:\", e)\n","        platform_report = classification_report(y_true, y_pred, digits=4)\n","\n","    print(f\"Platform Report:\\n{platform_report}\")\n","\n","print(f\"\\nAll outputs saved to: {save_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yMw5jP1gNrB4","executionInfo":{"status":"ok","timestamp":1752122158115,"user_tz":-330,"elapsed":113377,"user":{"displayName":"V T Rushi Kannan","userId":"06041568400969842982"}},"outputId":"0d91e188-5c6b-45e1-880a-fc5b7b3f71ed"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in validation CSV: ['text', 'level_1', 'level_2', 'level_3', 'source']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold 1 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 1: 100%|██████████| 20/20 [00:02<00:00,  6.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold 2 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 2: 100%|██████████| 20/20 [00:02<00:00,  7.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold 3 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 3: 100%|██████████| 20/20 [00:02<00:00,  7.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold 4 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 4: 100%|██████████| 20/20 [00:02<00:00,  7.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold 5 — loading model\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Predicting Fold 5: 100%|██████████| 20/20 [00:02<00:00,  7.17it/s]\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Ensemble Accuracy: 0.7598\n","F1 (Weighted): 0.7099\n","F1 (Macro):    0.4122\n","F1 (Micro):    0.7598\n","Precision (Macro): 0.6279\n","Recall (Macro):    0.4531\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","         0.0     0.5916    0.9200    0.7202       200\n","         1.0     0.9200    0.8768    0.8979       341\n","         2.0     1.0000    0.0156    0.0308        64\n","         3.0     0.0000    0.0000    0.0000        32\n","\n","    accuracy                         0.7598       637\n","   macro avg     0.6279    0.4531    0.4122       637\n","weighted avg     0.7787    0.7598    0.7099       637\n","\n","\n","\n","Platform-wise Evaluation:\n","\n","Platform: YOUTUBE\n","Accuracy: 0.8898\n","F1 Weighted: 0.8829\n","F1 Macro:    0.5951\n","Platform Report:\n","              precision    recall  f1-score   support\n","\n","         0.0     0.8291    1.0000    0.9066       131\n","         1.0     1.0000    0.7838    0.8788       111\n","         2.0     0.0000    0.0000    0.0000         0\n","         3.0     0.0000    0.0000    0.0000         3\n","\n","    accuracy                         0.8898       245\n","   macro avg     0.4573    0.4459    0.4463       245\n","weighted avg     0.8964    0.8898    0.8829       245\n","\n","\n","Platform: REDDIT\n","Accuracy: 0.8013\n","F1 Weighted: 0.7563\n","F1 Macro:    0.3836\n","Platform Report:\n","              precision    recall  f1-score   support\n","\n","         0.0     0.5263    0.7273    0.6107        55\n","         1.0     0.8918    0.9581    0.9238       215\n","         2.0     0.0000    0.0000    0.0000         9\n","         3.0     0.0000    0.0000    0.0000        28\n","\n","    accuracy                         0.8013       307\n","   macro avg     0.3545    0.4214    0.3836       307\n","weighted avg     0.7188    0.8013    0.7563       307\n","\n","\n","Platform: TWITTER\n","Accuracy: 0.2353\n","F1 Weighted: 0.1664\n","F1 Macro:    0.2167\n","Platform Report:\n","              precision    recall  f1-score   support\n","\n","         0.0     0.1688    0.9286    0.2857        14\n","         1.0     0.8571    0.4000    0.5455        15\n","         2.0     1.0000    0.0182    0.0357        55\n","         3.0     0.0000    0.0000    0.0000         1\n","\n","    accuracy                         0.2353        85\n","   macro avg     0.5065    0.3367    0.2167        85\n","weighted avg     0.8261    0.2353    0.1664        85\n","\n","\n","All outputs saved to: /content/drive/MyDrive/FIRE/outputs/ensemble_level3_eval\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"markdown","source":["# **TASK2**"],"metadata":{"id":"CAmQovkZOGgF"}},{"cell_type":"code","source":["import os\n","import json\n","import pandas as pd\n","from tabulate import tabulate\n","\n","# Base path\n","base_path = \"/content/drive/MyDrive/FIRE/Task2/fold_outputs\"\n","\n","# Valid class labels\n","possible_labels = [[\"0\", \"1\"], [\"Not Relevant\", \"Relevant\"]]\n","\n","# Loop over folds 1 to 5\n","for fold in range(1, 6):\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Fold {fold} Report\\n\")\n","\n","    fold_path = os.path.join(base_path, f\"fold_{fold}\")\n","    report_path = os.path.join(fold_path, \"final_report.json\")\n","\n","    if not os.path.exists(report_path):\n","        print(f\"Missing report: {report_path}\")\n","        continue\n","\n","    # Load report\n","    with open(report_path, \"r\") as f:\n","        report = json.load(f)\n","\n","    # Determine which label format to use\n","    label_keys = next((labels for labels in possible_labels if labels[0] in report), None)\n","\n","    if not label_keys:\n","        print(\"Could not detect label keys in report.\")\n","        continue\n","\n","    rows = []\n","    for label in label_keys:\n","        row = {\n","            \"Class\": label,\n","            \"Precision\": round(report[label][\"precision\"], 4),\n","            \"Recall\": round(report[label][\"recall\"], 4),\n","            \"F1-Score\": round(report[label][\"f1-score\"], 4),\n","            \"Support\": int(report[label][\"support\"])\n","        }\n","        rows.append(row)\n","\n","    # Add Accuracy + Macro & Weighted Avg\n","    rows.append({\n","        \"Class\": \"accuracy\",\n","        \"Precision\": \"\",\n","        \"Recall\": \"\",\n","        \"F1-Score\": round(report[\"accuracy\"], 4),\n","        \"Support\": sum(int(report[label][\"support\"]) for label in label_keys)\n","    })\n","\n","    for avg in [\"macro avg\", \"weighted avg\"]:\n","        rows.append({\n","            \"Class\": avg,\n","            \"Precision\": round(report[avg][\"precision\"], 4),\n","            \"Recall\": round(report[avg][\"recall\"], 4),\n","            \"F1-Score\": round(report[avg][\"f1-score\"], 4),\n","            \"Support\": int(report[avg][\"support\"])\n","        })\n","\n","    # Print as table\n","    df = pd.DataFrame(rows)\n","    print(tabulate(df, headers=\"keys\", tablefmt=\"github\", showindex=False))\n","\n","    # Summary\n","    print(f\"\\nFold {fold} Final Metrics:\")\n","    print(f\"Accuracy       : {report['accuracy']:.4f}\")\n","    print(f\"Macro F1       : {report['macro avg']['f1-score']:.4f}\")\n","    print(f\"Weighted F1    : {report['weighted avg']['f1-score']:.4f}\")\n","    print(f\"Macro Precision: {report['macro avg']['precision']:.4f}\")\n","    print(f\"Macro Recall   : {report['macro avg']['recall']:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wIhEckSlOFoI","executionInfo":{"status":"ok","timestamp":1752122195223,"user_tz":-330,"elapsed":6828,"user":{"displayName":"V T Rushi Kannan","userId":"06041568400969842982"}},"outputId":"80db5459-9205-4183-f27f-641e73c6d71b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Fold 1 Report\n","\n","| Class        | Precision   | Recall   |   F1-Score |   Support |\n","|--------------|-------------|----------|------------|-----------|\n","| 0            | 0.9019      | 0.97     |     0.9347 |      4161 |\n","| 1            | 0.6356      | 0.3318   |     0.436  |       657 |\n","| accuracy     |             |          |     0.8829 |      4818 |\n","| macro avg    | 0.7687      | 0.6509   |     0.6853 |      4818 |\n","| weighted avg | 0.8656      | 0.8829   |     0.8667 |      4818 |\n","\n","Fold 1 Final Metrics:\n","Accuracy       : 0.8829\n","Macro F1       : 0.6853\n","Weighted F1    : 0.8667\n","Macro Precision: 0.7687\n","Macro Recall   : 0.6509\n","\n","============================================================\n","Fold 2 Report\n","\n","| Class        | Precision   | Recall   |   F1-Score |   Support |\n","|--------------|-------------|----------|------------|-----------|\n","| 0            | 0.9074      | 0.9613   |     0.9336 |      4161 |\n","| 1            | 0.6073      | 0.379    |     0.4667 |       657 |\n","| accuracy     |             |          |     0.8819 |      4818 |\n","| macro avg    | 0.7574      | 0.6702   |     0.7002 |      4818 |\n","| weighted avg | 0.8665      | 0.8819   |     0.8699 |      4818 |\n","\n","Fold 2 Final Metrics:\n","Accuracy       : 0.8819\n","Macro F1       : 0.7002\n","Weighted F1    : 0.8699\n","Macro Precision: 0.7574\n","Macro Recall   : 0.6702\n","\n","============================================================\n","Fold 3 Report\n","\n","| Class        | Precision   | Recall   |   F1-Score |   Support |\n","|--------------|-------------|----------|------------|-----------|\n","| 0            | 0.8955      | 0.9825   |     0.937  |      4161 |\n","| 1            | 0.7115      | 0.274    |     0.3956 |       657 |\n","| accuracy     |             |          |     0.8858 |      4818 |\n","| macro avg    | 0.8035      | 0.6282   |     0.6663 |      4818 |\n","| weighted avg | 0.8704      | 0.8858   |     0.8631 |      4818 |\n","\n","Fold 3 Final Metrics:\n","Accuracy       : 0.8858\n","Macro F1       : 0.6663\n","Weighted F1    : 0.8631\n","Macro Precision: 0.8035\n","Macro Recall   : 0.6282\n","\n","============================================================\n","Fold 4 Report\n","\n","| Class        | Precision   | Recall   |   F1-Score |   Support |\n","|--------------|-------------|----------|------------|-----------|\n","| 0            | 0.9012      | 0.9728   |     0.9356 |      4161 |\n","| 1            | 0.6523      | 0.3232   |     0.4322 |       656 |\n","| accuracy     |             |          |     0.8844 |      4817 |\n","| macro avg    | 0.7767      | 0.648    |     0.6839 |      4817 |\n","| weighted avg | 0.8673      | 0.8844   |     0.8671 |      4817 |\n","\n","Fold 4 Final Metrics:\n","Accuracy       : 0.8844\n","Macro F1       : 0.6839\n","Weighted F1    : 0.8671\n","Macro Precision: 0.7767\n","Macro Recall   : 0.6480\n","\n","============================================================\n","Fold 5 Report\n","\n","| Class        | Precision   | Recall   |   F1-Score |   Support |\n","|--------------|-------------|----------|------------|-----------|\n","| 0            | 0.9014      | 0.975    |     0.9367 |      4161 |\n","| 1            | 0.6709      | 0.3232   |     0.4362 |       656 |\n","| accuracy     |             |          |     0.8862 |      4817 |\n","| macro avg    | 0.7861      | 0.6491   |     0.6865 |      4817 |\n","| weighted avg | 0.87        | 0.8862   |     0.8686 |      4817 |\n","\n","Fold 5 Final Metrics:\n","Accuracy       : 0.8862\n","Macro F1       : 0.6865\n","Weighted F1    : 0.8686\n","Macro Precision: 0.7861\n","Macro Recall   : 0.6491\n"]}]}]}