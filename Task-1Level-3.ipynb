{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2137607,
     "status": "error",
     "timestamp": 1751201278100,
     "user": {
      "displayName": "VT Rushi Kannan",
      "userId": "09227156192590121303"
     },
     "user_tz": -330
    },
    "id": "ZpkEVWk5g2od",
    "outputId": "118357d5-5ef4-492b-8cd7-5c55411f8905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Unique values in level_1 (train): [2 0 1]\n",
      "üîç Unique values in level_2 (train): [ 2.  0. nan  1.]\n",
      "\n",
      "üîÅ Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-3-692409783.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n",
      "[level3_fold1] Epoch 1:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold1] Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:51<00:00,  5.72it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 1: Train Loss = 270.5017 | Train Acc = 0.4150 | Train F1 = 0.3758 | Val Acc = 0.5444 | Val F1 = 0.3839\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold1] Epoch 2:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold1] Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:43<00:00,  6.77it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 2: Train Loss = 265.6484 | Train Acc = 0.5640 | Train F1 = 0.4558 | Val Acc = 0.7222 | Val F1 = 0.6716\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold1] Epoch 3:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold1] Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:49<00:00,  5.91it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 3: Train Loss = 240.0111 | Train Acc = 0.7496 | Train F1 = 0.6986 | Val Acc = 0.7803 | Val F1 = 0.7306\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold1] Epoch 4:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold1] Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.43it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 4: Train Loss = 224.9056 | Train Acc = 0.7830 | Train F1 = 0.7322 | Val Acc = 0.7889 | Val F1 = 0.7372\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold1] Epoch 5:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold1] Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:58<00:00,  4.98it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 5: Train Loss = 219.5839 | Train Acc = 0.7971 | Train F1 = 0.7506 | Val Acc = 0.7974 | Val F1 = 0.7447\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold1] Epoch 6:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold1] Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:46<00:00,  6.37it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 6: Train Loss = 216.8281 | Train Acc = 0.8110 | Train F1 = 0.7728 | Val Acc = 0.7983 | Val F1 = 0.7557\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold1] Epoch 7:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold1] Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:47<00:00,  6.11it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 7: Train Loss = 213.0904 | Train Acc = 0.8238 | Train F1 = 0.7929 | Val Acc = 0.8043 | Val F1 = 0.7640\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold1] Epoch 8:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold1] Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:46<00:00,  6.30it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 8: Train Loss = 214.5947 | Train Acc = 0.8249 | Train F1 = 0.7943 | Val Acc = 0.8060 | Val F1 = 0.7708\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold1.pth\n",
      "\n",
      "üîÅ Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-3-692409783.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n",
      "[level3_fold2] Epoch 1:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold2] Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:55<00:00,  5.24it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 1: Train Loss = 271.9362 | Train Acc = 0.5020 | Train F1 = 0.3799 | Val Acc = 0.5436 | Val F1 = 0.3829\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold2] Epoch 2:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold2] Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:46<00:00,  6.25it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 2: Train Loss = 267.1633 | Train Acc = 0.5407 | Train F1 = 0.3902 | Val Acc = 0.5436 | Val F1 = 0.3829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold2] Epoch 3:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold2] Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.42it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 3: Train Loss = 252.0105 | Train Acc = 0.6588 | Train F1 = 0.5958 | Val Acc = 0.7615 | Val F1 = 0.7095\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold2] Epoch 4:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold2] Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.42it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 4: Train Loss = 227.9157 | Train Acc = 0.7734 | Train F1 = 0.7231 | Val Acc = 0.7812 | Val F1 = 0.7298\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold2] Epoch 5:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold2] Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.42it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 5: Train Loss = 222.3213 | Train Acc = 0.7875 | Train F1 = 0.7431 | Val Acc = 0.7923 | Val F1 = 0.7410\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold2] Epoch 6:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold2] Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.47it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 6: Train Loss = 219.5630 | Train Acc = 0.8014 | Train F1 = 0.7670 | Val Acc = 0.7932 | Val F1 = 0.7442\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold2] Epoch 7:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold2] Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:46<00:00,  6.28it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 7: Train Loss = 217.5133 | Train Acc = 0.8097 | Train F1 = 0.7791 | Val Acc = 0.7863 | Val F1 = 0.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold2] Epoch 8:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold2] Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:42<00:00,  6.86it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 8: Train Loss = 214.3938 | Train Acc = 0.8123 | Train F1 = 0.7866 | Val Acc = 0.7863 | Val F1 = 0.7428\n",
      "\n",
      "üîÅ Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-3-692409783.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n",
      "[level3_fold3] Epoch 1:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold3] Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:42<00:00,  6.84it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 1: Train Loss = 274.1547 | Train Acc = 0.3957 | Train F1 = 0.3540 | Val Acc = 0.5441 | Val F1 = 0.3834\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold3] Epoch 2:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold3] Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:43<00:00,  6.74it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 2: Train Loss = 267.1848 | Train Acc = 0.5481 | Train F1 = 0.3996 | Val Acc = 0.6039 | Val F1 = 0.5083\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold3] Epoch 3:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold3] Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.40it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 3: Train Loss = 240.6250 | Train Acc = 0.7435 | Train F1 = 0.6926 | Val Acc = 0.7725 | Val F1 = 0.7215\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold3] Epoch 4:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold3] Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.39it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 4: Train Loss = 226.7806 | Train Acc = 0.7822 | Train F1 = 0.7309 | Val Acc = 0.7810 | Val F1 = 0.7295\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold3] Epoch 5:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold3] Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.41it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 5: Train Loss = 223.6059 | Train Acc = 0.7903 | Train F1 = 0.7380 | Val Acc = 0.7870 | Val F1 = 0.7337\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold3] Epoch 6:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold3] Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:46<00:00,  6.34it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 6: Train Loss = 219.9893 | Train Acc = 0.7963 | Train F1 = 0.7479 | Val Acc = 0.7930 | Val F1 = 0.7406\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold3] Epoch 7:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold3] Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.43it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 7: Train Loss = 216.3455 | Train Acc = 0.8063 | Train F1 = 0.7587 | Val Acc = 0.7947 | Val F1 = 0.7428\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold3] Epoch 8:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold3] Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.47it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 8: Train Loss = 215.3091 | Train Acc = 0.8087 | Train F1 = 0.7635 | Val Acc = 0.7930 | Val F1 = 0.7399\n",
      "\n",
      "üîÅ Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-3-692409783.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n",
      "[level3_fold4] Epoch 1:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold4] Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:42<00:00,  6.86it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 1: Train Loss = 271.6054 | Train Acc = 0.4528 | Train F1 = 0.4219 | Val Acc = 0.5449 | Val F1 = 0.3844\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold4] Epoch 2:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold4] Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:43<00:00,  6.74it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 2: Train Loss = 268.1300 | Train Acc = 0.5442 | Train F1 = 0.3958 | Val Acc = 0.5449 | Val F1 = 0.3844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold4] Epoch 3:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold4] Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:42<00:00,  6.84it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 3: Train Loss = 266.2803 | Train Acc = 0.5622 | Train F1 = 0.4598 | Val Acc = 0.6595 | Val F1 = 0.5948\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold4] Epoch 4:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold4] Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:47<00:00,  6.16it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 4: Train Loss = 242.2841 | Train Acc = 0.7204 | Train F1 = 0.6713 | Val Acc = 0.7784 | Val F1 = 0.7289\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold4] Epoch 5:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold4] Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:46<00:00,  6.34it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 5: Train Loss = 226.7863 | Train Acc = 0.7700 | Train F1 = 0.7265 | Val Acc = 0.7887 | Val F1 = 0.7351\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r[level3_fold4] Epoch 6:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold4] Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.38it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 6: Train Loss = 221.0464 | Train Acc = 0.7926 | Train F1 = 0.7539 | Val Acc = 0.7913 | Val F1 = 0.7427\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold4] Epoch 7:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold4] Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:46<00:00,  6.31it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 7: Train Loss = 218.9074 | Train Acc = 0.7950 | Train F1 = 0.7571 | Val Acc = 0.7956 | Val F1 = 0.7553\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold4] Epoch 8:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold4] Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:46<00:00,  6.31it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 8: Train Loss = 217.8447 | Train Acc = 0.8021 | Train F1 = 0.7697 | Val Acc = 0.7947 | Val F1 = 0.7550\n",
      "\n",
      "üîÅ Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-3-692409783.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n",
      "[level3_fold5] Epoch 1:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold5] Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:42<00:00,  6.81it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 1: Train Loss = 271.6637 | Train Acc = 0.4590 | Train F1 = 0.4282 | Val Acc = 0.5449 | Val F1 = 0.3844\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold5] Epoch 2:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold5] Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:43<00:00,  6.70it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 2: Train Loss = 266.6303 | Train Acc = 0.5552 | Train F1 = 0.4313 | Val Acc = 0.6048 | Val F1 = 0.5280\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold5] Epoch 3:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold5] Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.43it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 3: Train Loss = 238.7289 | Train Acc = 0.7347 | Train F1 = 0.6902 | Val Acc = 0.7759 | Val F1 = 0.7238\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold5] Epoch 4:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold5] Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:46<00:00,  6.37it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 4: Train Loss = 225.6900 | Train Acc = 0.7792 | Train F1 = 0.7421 | Val Acc = 0.7827 | Val F1 = 0.7293\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold5] Epoch 5:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold5] Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.37it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 5: Train Loss = 219.2373 | Train Acc = 0.8046 | Train F1 = 0.7760 | Val Acc = 0.8067 | Val F1 = 0.7838\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold5] Epoch 6:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold5] Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:46<00:00,  6.33it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 6: Train Loss = 214.7002 | Train Acc = 0.8275 | Train F1 = 0.8109 | Val Acc = 0.8135 | Val F1 = 0.7941\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold5] Epoch 7:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold5] Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.44it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 7: Train Loss = 211.0344 | Train Acc = 0.8369 | Train F1 = 0.8227 | Val Acc = 0.8221 | Val F1 = 0.8112\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[level3_fold5] Epoch 8:   0%|          | 0/293 [00:00<?, ?it/s]/tmp/ipython-input-3-692409783.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "[level3_fold5] Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [00:45<00:00,  6.41it/s]\n",
      "/tmp/ipython-input-3-692409783.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 8: Train Loss = 211.2309 | Train Acc = 0.8452 | Train F1 = 0.8358 | Val Acc = 0.8221 | Val F1 = 0.8131\n",
      "üíæ Model saved at: /content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold5.pth\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3-692409783.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mlevel3_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mpred_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel3_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mmajority\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel3_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import os, pickle, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification, get_cosine_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "VAL_BATCH_SIZE = 32\n",
    "MAX_LEN = 128\n",
    "EPOCHS = 8\n",
    "PATIENCE = 3\n",
    "LR = 2e-5\n",
    "MODEL_NAME = \"microsoft/deberta-v3-small\"\n",
    "BASE_DIR = \"/content/drive/MyDrive/FIRE\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------- UTILS --------------------\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed()\n",
    "\n",
    "# -------------------- DATASET --------------------\n",
    "class CryptoDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"text\": self.texts[idx],\n",
    "            \"label\": self.labels[idx]\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts = [x[\"text\"] for x in batch]\n",
    "    labels = torch.tensor([x[\"label\"] for x in batch], dtype=torch.long)\n",
    "    encoding = tokenizer(texts, padding=True, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "    return {\n",
    "        \"input_ids\": encoding[\"input_ids\"],\n",
    "        \"attention_mask\": encoding[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# -------------------- LOSSES --------------------\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, label_smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.alpha = torch.tensor(alpha).to(device) if alpha else None\n",
    "        self.gamma = gamma\n",
    "        self.smoothing = label_smoothing\n",
    "    def forward(self, logits, target):\n",
    "        ce = torch.nn.functional.cross_entropy(logits, target, reduction='none', label_smoothing=self.smoothing)\n",
    "        pt = torch.exp(-ce)\n",
    "        focal = (1 - pt) ** self.gamma * ce\n",
    "        if self.alpha is not None:\n",
    "            focal = self.alpha[target] * focal\n",
    "        return focal.mean()\n",
    "\n",
    "def supervised_contrastive_loss(embeddings, labels, temperature=0.3):\n",
    "    norm = torch.nn.functional.normalize(embeddings, dim=1)\n",
    "    sim = torch.matmul(norm, norm.T) / temperature\n",
    "    labels = labels.view(-1, 1)\n",
    "    mask = torch.eq(labels, labels.T).float().to(device)\n",
    "    logits_mask = 1 - torch.eye(mask.size(0)).to(device)\n",
    "    mask *= logits_mask\n",
    "    exp_logits = torch.exp(sim) * logits_mask\n",
    "    log_prob = sim - torch.log(exp_logits.sum(1, keepdim=True) + 1e-12)\n",
    "    return -(mask * log_prob).sum(1).div(mask.sum(1) + 1e-12).mean()\n",
    "\n",
    "# -------------------- TRAIN FUNCTION --------------------\n",
    "def train_level3_model(\n",
    "    train_loader, val_loader, save_path, y_train_labels,\n",
    "    num_labels=4, contrastive_weight=0.3, level_name=\"level3_fold\", use_amp=True\n",
    "):\n",
    "    model = DebertaV2ForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels, output_hidden_states=True).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    total_steps = len(train_loader) * EPOCHS\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, 0.1 * total_steps, total_steps)\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "    class_counts = np.bincount(y_train_labels)\n",
    "    class_weights = 1.0 / (np.log(1.01 + class_counts))\n",
    "    class_weights = class_weights / class_weights.sum()\n",
    "    focal_loss = FocalLoss(alpha=class_weights.tolist(), gamma=2.0, label_smoothing=0.1)\n",
    "\n",
    "    best_f1, patience_counter = -1, 0\n",
    "    train_loss_hist, val_f1_hist, train_f1_hist, train_acc_hist, val_acc_hist = [], [], [], [], []\n",
    "    log_file_path = save_path.replace(\".pth\", \"_log.txt\")\n",
    "    with open(log_file_path, \"w\") as log_file:\n",
    "        for epoch in range(EPOCHS):\n",
    "            model.train(); total_loss = 0; preds, targets = [], []\n",
    "            for batch in tqdm(train_loader, desc=f\"[{level_name}] Epoch {epoch+1}\"):\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                optimizer.zero_grad()\n",
    "                with autocast(enabled=use_amp):\n",
    "                    out = model(**batch)\n",
    "                    logits = out.logits\n",
    "                    cls_emb = out.hidden_states[-1][:, 0]\n",
    "                    loss = focal_loss(logits, batch[\"labels\"])\n",
    "                    if batch[\"labels\"].unique().numel() > 1:\n",
    "                        loss += contrastive_weight * supervised_contrastive_loss(cls_emb, batch[\"labels\"])\n",
    "                scaler.scale(loss).backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "                total_loss += loss.item()\n",
    "                preds += logits.argmax(dim=-1).cpu().tolist()\n",
    "                targets += batch[\"labels\"].cpu().tolist()\n",
    "\n",
    "            train_loss_hist.append(total_loss)\n",
    "            train_acc = accuracy_score(targets, preds)\n",
    "            train_f1 = f1_score(targets, preds, average=\"weighted\")\n",
    "            train_f1_hist.append(train_f1)\n",
    "            train_acc_hist.append(train_acc)\n",
    "\n",
    "            model.eval(); val_preds, val_targets = [], []\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                    with autocast(enabled=use_amp):\n",
    "                        logits = model(**batch).logits\n",
    "                    val_preds += logits.argmax(dim=-1).cpu().tolist()\n",
    "                    val_targets += batch[\"labels\"].cpu().tolist()\n",
    "            val_f1 = f1_score(val_targets, val_preds, average=\"weighted\")\n",
    "            val_acc = accuracy_score(val_targets, val_preds)\n",
    "            val_f1_hist.append(val_f1)\n",
    "            val_acc_hist.append(val_acc)\n",
    "\n",
    "            line = f\" Epoch {epoch+1}: Train Loss = {total_loss:.4f} | Train Acc = {train_acc:.4f} | Train F1 = {train_f1:.4f} | Val Acc = {val_acc:.4f} | Val F1 = {val_f1:.4f}\"\n",
    "            print(line)\n",
    "            log_file.write(line + \"\\n\")\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1\n",
    "                patience_counter = 0\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                print(f\" Model saved at: {save_path}\")\n",
    "                log_file.write(f\"Saved model: {save_path}\\n\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= PATIENCE:\n",
    "                    print(\" Early stopping\")\n",
    "                    log_file.write(\"Early stopping\\n\")\n",
    "                    break\n",
    "\n",
    "    # Plot & log\n",
    "    plot_path = save_path.replace(\".pth\", \"_plot.png\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_loss_hist, label=\"Train Loss\")\n",
    "    plt.plot(train_f1_hist, label=\"Train F1\")\n",
    "    plt.plot(train_acc_hist, label=\"Train Acc\")\n",
    "    plt.plot(val_f1_hist, label=\"Val F1\")\n",
    "    plt.plot(val_acc_hist, label=\"Val Acc\")\n",
    "    plt.title(f\"{level_name} Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(), plt.grid(True)\n",
    "    plt.savefig(plot_path); plt.close()\n",
    "    return model\n",
    "\n",
    "# -------------------- MAIN SCRIPT --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = os.path.join(BASE_DIR, f\"run_{run_id}\")\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    for sub in [\"models\", \"logs\", \"plots\", \"encoders\"]: os.makedirs(os.path.join(run_dir, sub), exist_ok=True)\n",
    "\n",
    "    train_df = pd.read_csv(f\"{BASE_DIR}/crypto_task1_train.csv\")\n",
    "    val_df = pd.read_csv(f\"{BASE_DIR}/crypto_task1_val.csv\")\n",
    "\n",
    "    print(\" Unique values in level_1 (train):\", train_df[\"level_1\"].unique())\n",
    "    print(\" Unique values in level_2 (train):\", train_df[\"level_2\"].unique())\n",
    "\n",
    "    train_l3_df = train_df[(train_df[\"level_1\"] == 2) & (train_df[\"level_2\"] == 0)].copy().reset_index(drop=True)\n",
    "    val_l3_df = val_df[(val_df[\"level_1\"] == 2) & (val_df[\"level_2\"] == 0)].copy().reset_index(drop=True)\n",
    "\n",
    "    if train_l3_df.empty:\n",
    "        print(\" No NEUTRAL samples found in level_2 under SUBJECTIVE. Skipping Level 3 training.\")\n",
    "    else:\n",
    "        le3 = LabelEncoder()\n",
    "        train_l3_df[\"level_3_enc\"] = le3.fit_transform(train_l3_df[\"level_3\"])\n",
    "        val_l3_df[\"level_3_enc\"] = le3.transform(val_l3_df[\"level_3\"])\n",
    "        pickle.dump(le3, open(f\"{run_dir}/encoders/label_encoder_level_3.pkl\", \"wb\"))\n",
    "\n",
    "        tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "        level3_preds, level3_labels = [], []\n",
    "\n",
    "        for fold, (tr_idx, va_idx) in enumerate(skf.split(train_l3_df, train_l3_df[\"level_3_enc\"])):\n",
    "            print(f\"\\n Fold {fold+1}/5\")\n",
    "            tr_df = train_l3_df.loc[tr_idx].reset_index(drop=True)\n",
    "            va_df = train_l3_df.loc[va_idx].reset_index(drop=True)\n",
    "            tr_loader = DataLoader(CryptoDataset(tr_df[\"text\"], tr_df[\"level_3_enc\"], tokenizer), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "            va_loader = DataLoader(CryptoDataset(va_df[\"text\"], va_df[\"level_3_enc\"], tokenizer), batch_size=VAL_BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "            save_path = os.path.join(run_dir, \"models\", f\"level3_fold{fold+1}.pth\")\n",
    "\n",
    "            model = train_level3_model(\n",
    "                tr_loader, va_loader, save_path,\n",
    "                y_train_labels=tr_df[\"level_3_enc\"].values,\n",
    "                level_name=f\"level3_fold{fold+1}\"\n",
    "            )\n",
    "\n",
    "            model.eval(); preds, targets = [], []\n",
    "            with torch.no_grad():\n",
    "                for batch in va_loader:\n",
    "                    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                    logits = model(**batch).logits\n",
    "                    preds += logits.argmax(dim=-1).cpu().tolist()\n",
    "                    targets += batch[\"labels\"].cpu().tolist()\n",
    "            level3_preds.append(preds)\n",
    "            level3_labels.append(targets)\n",
    "\n",
    "        pred_matrix = np.array(level3_preds)\n",
    "        majority = mode(pred_matrix, axis=0).mode[0]\n",
    "        true_labels = np.array(level3_labels[0])\n",
    "        acc = accuracy_score(true_labels, majority)\n",
    "        f1 = f1_score(true_labels, majority, average=\"weighted\")\n",
    "        print(f\"\\n Level 3 Ensemble Accuracy: {acc:.4f} | F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33412,
     "status": "ok",
     "timestamp": 1751201376867,
     "user": {
      "displayName": "VT Rushi Kannan",
      "userId": "09227156192590121303"
     },
     "user_tz": -330
    },
    "id": "Aebk4Lz9o1AD",
    "outputId": "fdabedff-bf38-4cb4-bacb-3a63b4c4eca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Columns in validation CSV: ['text', 'level_1', 'level_2', 'level_3', 'source']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Fold 1 ‚Äî loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Fold 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:02<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Fold 2 ‚Äî loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Fold 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:02<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Fold 3 ‚Äî loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Fold 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:02<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Fold 4 ‚Äî loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Fold 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:02<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Fold 5 ‚Äî loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Fold 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:02<00:00,  7.40it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Ensemble Accuracy: 0.7598\n",
      "üéØ F1 (Weighted): 0.7099\n",
      "üìè F1 (Macro):    0.4122\n",
      "üìê F1 (Micro):    0.7598\n",
      "üéØ Precision (Macro): 0.6279\n",
      "üìå Recall (Macro):    0.4531\n",
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5916    0.9200    0.7202       200\n",
      "         1.0     0.9200    0.8768    0.8979       341\n",
      "         2.0     1.0000    0.0156    0.0308        64\n",
      "         3.0     0.0000    0.0000    0.0000        32\n",
      "\n",
      "    accuracy                         0.7598       637\n",
      "   macro avg     0.6279    0.4531    0.4122       637\n",
      "weighted avg     0.7787    0.7598    0.7099       637\n",
      "\n",
      "\n",
      "\n",
      "üîé Platform-wise Evaluation:\n",
      "\n",
      "üì¶ Platform: YOUTUBE\n",
      "Accuracy: 0.8898\n",
      "F1 Weighted: 0.8829\n",
      "F1 Macro:    0.5951\n",
      "Platform Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8291    1.0000    0.9066       131\n",
      "         1.0     1.0000    0.7838    0.8788       111\n",
      "         2.0     0.0000    0.0000    0.0000         0\n",
      "         3.0     0.0000    0.0000    0.0000         3\n",
      "\n",
      "    accuracy                         0.8898       245\n",
      "   macro avg     0.4573    0.4459    0.4463       245\n",
      "weighted avg     0.8964    0.8898    0.8829       245\n",
      "\n",
      "\n",
      "üì¶ Platform: REDDIT\n",
      "Accuracy: 0.8013\n",
      "F1 Weighted: 0.7563\n",
      "F1 Macro:    0.3836\n",
      "Platform Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5263    0.7273    0.6107        55\n",
      "         1.0     0.8918    0.9581    0.9238       215\n",
      "         2.0     0.0000    0.0000    0.0000         9\n",
      "         3.0     0.0000    0.0000    0.0000        28\n",
      "\n",
      "    accuracy                         0.8013       307\n",
      "   macro avg     0.3545    0.4214    0.3836       307\n",
      "weighted avg     0.7188    0.8013    0.7563       307\n",
      "\n",
      "\n",
      "üì¶ Platform: TWITTER\n",
      "Accuracy: 0.2353\n",
      "F1 Weighted: 0.1664\n",
      "F1 Macro:    0.2167\n",
      "Platform Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.1688    0.9286    0.2857        14\n",
      "         1.0     0.8571    0.4000    0.5455        15\n",
      "         2.0     1.0000    0.0182    0.0357        55\n",
      "         3.0     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.2353        85\n",
      "   macro avg     0.5065    0.3367    0.2167        85\n",
      "weighted avg     0.8261    0.2353    0.1664        85\n",
      "\n",
      "\n",
      "‚úÖ All outputs saved to: /content/drive/MyDrive/FIRE/outputs/ensemble_level3_eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# === CONFIRMED LEVEL 3 INFERENCE & EVALUATION SCRIPT ===\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from scipy.stats import mode\n",
    "from transformers import DebertaV2ForSequenceClassification, AutoTokenizer\n",
    "import pickle\n",
    "\n",
    "# === CONFIG ===\n",
    "model_paths = [\n",
    "    \"/content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold1.pth\",\n",
    "    \"/content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold2.pth\",\n",
    "    \"/content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold3.pth\",\n",
    "    \"/content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold4.pth\",\n",
    "    \"/content/drive/MyDrive/FIRE/run_20250629_121221/models/level3_fold5.pth\",\n",
    "]\n",
    "model_name = \"microsoft/deberta-v3-small\"\n",
    "label_encoder_path = \"/content/drive/MyDrive/FIRE/run_20250629_121221/encoders/label_encoder_level_3.pkl\"\n",
    "val_csv_path = \"/content/drive/MyDrive/FIRE/crypto_task1_val.csv\"\n",
    "save_dir = \"/content/drive/MyDrive/FIRE/outputs/ensemble_level3_eval\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# === Load label encoder ===\n",
    "with open(label_encoder_path, \"rb\") as f:\n",
    "    le3 = pickle.load(f)\n",
    "\n",
    "# === Load and preprocess validation data ===\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "print(\"Columns in validation CSV:\", val_df.columns.tolist())\n",
    "\n",
    "val_df['source_token'] = val_df['source'].str.upper().map({\n",
    "    'REDDIT': '[REDDIT]',\n",
    "    'TWITTER': '[TWITTER]',\n",
    "    'YOUTUBE': '[YOUTUBE]'\n",
    "})\n",
    "val_df['text'] = val_df['source_token'] + ' ' + val_df['text']\n",
    "\n",
    "# Only NEUTRAL under SUBJECTIVE are valid for Level 3\n",
    "val_df = val_df[(val_df['level_1'] == 2) & (val_df['level_2'] == 0)].copy()\n",
    "val_df[\"level_3_enc\"] = le3.transform(val_df[\"level_3\"])\n",
    "true_labels = val_df[\"level_3_enc\"].values\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "encodings = tokenizer(\n",
    "    list(val_df['text']),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "labels = torch.tensor(true_labels)\n",
    "val_dataset = torch.utils.data.TensorDataset(\n",
    "    encodings['input_ids'], encodings['attention_mask'], labels\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# === Inference ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "all_fold_preds = []\n",
    "\n",
    "for fold, model_path in enumerate(model_paths):\n",
    "    print(f\"\\nFold {fold+1} ‚Äî loading model\")\n",
    "    model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=len(le3.classes_)\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Predicting Fold {fold+1}\"):\n",
    "            input_ids, attention_mask, _ = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            fold_preds.extend(preds)\n",
    "\n",
    "    all_fold_preds.append(np.array(fold_preds))\n",
    "\n",
    "# === Majority Voting ===\n",
    "ensemble_preds = mode(np.array(all_fold_preds), axis=0).mode.squeeze()\n",
    "pred_labels = le3.inverse_transform(ensemble_preds)\n",
    "\n",
    "# Save predictions\n",
    "val_df[\"preds\"] = ensemble_preds\n",
    "val_df[\"pred_labels\"] = pred_labels\n",
    "val_df.to_csv(os.path.join(save_dir, \"level3_val_predictions.csv\"), index=False)\n",
    "\n",
    "# === Overall Metrics ===\n",
    "acc = accuracy_score(true_labels, ensemble_preds)\n",
    "f1_weighted = f1_score(true_labels, ensemble_preds, average='weighted')\n",
    "f1_macro = f1_score(true_labels, ensemble_preds, average='macro')\n",
    "f1_micro = f1_score(true_labels, ensemble_preds, average='micro')\n",
    "prec_macro = precision_score(true_labels, ensemble_preds, average='macro')\n",
    "recall_macro = recall_score(true_labels, ensemble_preds, average='macro')\n",
    "\n",
    "try:\n",
    "    report = classification_report(\n",
    "        true_labels,\n",
    "        ensemble_preds,\n",
    "        labels=list(range(len(le3.classes_))),\n",
    "        target_names=[str(c) for c in le3.classes_],\n",
    "        digits=4\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Error generating classification report:\", e)\n",
    "    report = classification_report(true_labels, ensemble_preds, digits=4)\n",
    "\n",
    "metrics_text = f\"\"\"\n",
    "Ensemble Accuracy: {acc:.4f}\n",
    "F1 (Weighted): {f1_weighted:.4f}\n",
    "F1 (Macro):    {f1_macro:.4f}\n",
    "F1 (Micro):    {f1_micro:.4f}\n",
    "Precision (Macro): {prec_macro:.4f}\n",
    "Recall (Macro):    {recall_macro:.4f}\n",
    "\n",
    "Classification Report:\n",
    "{report}\n",
    "\"\"\"\n",
    "\n",
    "print(metrics_text)\n",
    "with open(os.path.join(save_dir, \"metrics.txt\"), \"w\") as f:\n",
    "    f.write(metrics_text)\n",
    "\n",
    "# === Confusion Matrix ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "cm = confusion_matrix(true_labels, ensemble_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix (Level 3 Ensemble)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"confusion_matrix.png\"))\n",
    "plt.close()\n",
    "\n",
    "# === Platform-wise Evaluation\n",
    "print(\"\\nPlatform-wise Evaluation:\")\n",
    "platforms = [\"youtube\", \"reddit\", \"twitter\"]\n",
    "\n",
    "for platform in platforms:\n",
    "    mask = val_df['source'].str.lower() == platform\n",
    "    y_true = val_df[\"level_3_enc\"].values[mask]\n",
    "    y_pred = val_df[\"preds\"].values[mask]\n",
    "\n",
    "    print(f\"\\nPlatform: {platform.upper()}\")\n",
    "    if len(y_true) == 0:\n",
    "        print(f\"No samples for {platform.upper()}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Weighted: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"F1 Macro:    {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "\n",
    "    try:\n",
    "        platform_report = classification_report(\n",
    "            y_true, y_pred,\n",
    "            labels=list(range(len(le3.classes_))),\n",
    "            target_names=[str(c) for c in le3.classes_],\n",
    "            digits=4\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Error generating report:\", e)\n",
    "        platform_report = classification_report(y_true, y_pred, digits=4)\n",
    "\n",
    "    print(f\"Platform Report:\\n{platform_report}\")\n",
    "\n",
    "print(f\"\\nAll outputs saved to: {save_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO+pLcyrWVfv1RrscxBwFkC",
   "mount_file_id": "1KO5HmL205Vy1RFfBBLI64wOFjPf2Mvlm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "026946106a0a4898a4ed27af1f90972a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d57cf75def4f769b8e3dfdfbd5d185": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ec7e1d958f448bebf51382d090a72d3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d349dde5e4214e308c4e30902fe26eb9",
      "value": "tokenizer_config.json:‚Äá100%"
     }
    },
    "09a723d805f9480f8e3be5f40c599a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c1c2da471444c589ace962b66e92658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38a1725cba214785b84ed19c544b1b46",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_fe0785eeda2c4aaf8b96fa35fd67a7ce",
      "value": "‚Äá578/578‚Äá[00:00&lt;00:00,‚Äá29.8kB/s]"
     }
    },
    "0c3d13a6100a4156ae0cb7fe2850867d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8be996f677e46849e0f0157dd390c66",
      "max": 578,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ac2577a08be24dea9ffbded4a50fe8f9",
      "value": 578
     }
    },
    "2b83c235cbb04254b8a53805ceec4835": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38a1725cba214785b84ed19c544b1b46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cf72ffaa4e346f8b116bc6984decd44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3e4b37007338486f9a1bc42d92e66676": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e771d40c267645dcb2033ac56f2bdf25",
       "IPY_MODEL_0c3d13a6100a4156ae0cb7fe2850867d",
       "IPY_MODEL_0c1c2da471444c589ace962b66e92658"
      ],
      "layout": "IPY_MODEL_9972a70aad4045f6b7fa063f316a5f0e"
     }
    },
    "4d914ae7555b4ddd9748393ce7c1b9f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ec7e1d958f448bebf51382d090a72d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "721e119e9c664d1492ff38a7b2ec8752": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c3cdc5c057d247ddb2086a129cbb7a84",
       "IPY_MODEL_fdb89591f9be4739ba5ddb26470437d3",
       "IPY_MODEL_f415f2171d814452bd3fa9c3bab8b70d"
      ],
      "layout": "IPY_MODEL_026946106a0a4898a4ed27af1f90972a"
     }
    },
    "7ff248e227534f1fb063383982171076": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8760dd9c441b4477be9a56ae2e051964": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8dd65ceaca524e38b96e43f29b25930d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "935630bf0cef48418db6b4b28fb32475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97bba8001ec64367ade6f56ec2cfef80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9972a70aad4045f6b7fa063f316a5f0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fc47a2f2a184ff5be80bd5f26d29aaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_08d57cf75def4f769b8e3dfdfbd5d185",
       "IPY_MODEL_a90b4e5d1b114d5fa38248d03bce3bb5",
       "IPY_MODEL_fc36432f67324730aaad16eaed80fd3b"
      ],
      "layout": "IPY_MODEL_2b83c235cbb04254b8a53805ceec4835"
     }
    },
    "a8be996f677e46849e0f0157dd390c66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a90b4e5d1b114d5fa38248d03bce3bb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa8158d2f0034e88b91112a0d59c39e5",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3cf72ffaa4e346f8b116bc6984decd44",
      "value": 52
     }
    },
    "ac2577a08be24dea9ffbded4a50fe8f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3cdc5c057d247ddb2086a129cbb7a84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d83ca0d931b2453eb53dcfabff88fcd8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8dd65ceaca524e38b96e43f29b25930d",
      "value": "spm.model:‚Äá100%"
     }
    },
    "cd4f66ca38504c1db54d327b501f3b2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d349dde5e4214e308c4e30902fe26eb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d83ca0d931b2453eb53dcfabff88fcd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df6801a544554ac18106282c0fc44511": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e771d40c267645dcb2033ac56f2bdf25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8760dd9c441b4477be9a56ae2e051964",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_4d914ae7555b4ddd9748393ce7c1b9f3",
      "value": "config.json:‚Äá100%"
     }
    },
    "f415f2171d814452bd3fa9c3bab8b70d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ff248e227534f1fb063383982171076",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_09a723d805f9480f8e3be5f40c599a44",
      "value": "‚Äá2.46M/2.46M‚Äá[00:00&lt;00:00,‚Äá33.5MB/s]"
     }
    },
    "fa8158d2f0034e88b91112a0d59c39e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc36432f67324730aaad16eaed80fd3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df6801a544554ac18106282c0fc44511",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_97bba8001ec64367ade6f56ec2cfef80",
      "value": "‚Äá52.0/52.0‚Äá[00:00&lt;00:00,‚Äá1.99kB/s]"
     }
    },
    "fdb89591f9be4739ba5ddb26470437d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_935630bf0cef48418db6b4b28fb32475",
      "max": 2464616,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd4f66ca38504c1db54d327b501f3b2a",
      "value": 2464616
     }
    },
    "fe0785eeda2c4aaf8b96fa35fd67a7ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
